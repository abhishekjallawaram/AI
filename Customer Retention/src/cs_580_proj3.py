# -*- coding: utf-8 -*-
"""CS-580_Proj3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hd6BSoafYt4HS0PDLBKEkB-UBN0xgHGz
"""

import re
import numpy as np
import pandas as pd
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.decomposition import PCA
from sklearn.decomposition import SparsePCA
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import BernoulliNB,GaussianNB
from imblearn.over_sampling import SMOTE
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import random
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import TruncatedSVD
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,f1_score,make_scorer
from sklearn.feature_selection import chi2
from sklearn.feature_selection import SelectKBest
from sklearn.impute import SimpleImputer
from sklearn.model_selection import ShuffleSplit,cross_val_score

bank_data = pd.read_csv("/content/drive/MyDrive/bank-additional-full.csv", sep=';')
bank_data.info()
print(bank_data.shape)
bank_data.head(7)

bank_data.describe()

#!pip install pandas-profiling==3.4.0
#from pandas_profiling import ProfileReport
#profile = ProfileReport(bank_data)
#profile

#profile.to_file(output_file="pandas_profiling1.html")

y_label = bank_data['y']
final_values = {'yes':1,'no':0}
y_label = y_label.map(lambda value: final_values[value])
y_label.head(5)

bank_data_1 = bank_data.copy()
bank_data_1.drop(['y'],axis=1,inplace = True)
bank_data.drop(['y'],axis=1,inplace = True)
bank_data_1.drop(['default','contact','month','day_of_week','duration','pdays'],axis=1,inplace = True)
print(bank_data_1.shape)
print(bank_data.shape)

bank_data.isnull().sum()

y_label.value_counts()

X_train, X_test, y_train, y_test = train_test_split(bank_data, y_label, test_size=0.2, random_state=0)
cv_X_train, cv_X_test, cv_y_train, cv_y_test = train_test_split(X_train, y_train, test_size=0.2)
X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(bank_data_1, y_label, test_size=0.2, random_state=0)
cv_X_train_1, cv_X_test_1, cv_y_train_1, cv_y_test_1 = train_test_split(X_train_1, y_train_1, test_size=0.2)

X_train.head(5)

X_train1, X_test1, y_train1, y_test1 = train_test_split(bank_data, y_label, test_size=0.2, random_state=0)
cv_X_train1, cv_X_test1, cv_y_train1, cv_y_test1 = train_test_split(X_train1, y_train1, test_size=0.2)
X_train1_1, X_test1_1, y_train1_1, y_test_1 = train_test_split(bank_data_1, y_label, test_size=0.2, random_state=0)
cv_X_train1_1, cv_X_test1_1, cv_y_train1_1, cv_y_test_1 = train_test_split(X_train1_1, y_train1_1, test_size=0.2)

from sklearn.preprocessing import OneHotEncoder
OneHot_enc = OneHotEncoder(handle_unknown="ignore", sparse=False)
OneHot_enc_1 = OneHotEncoder(handle_unknown="ignore", sparse=False)

categorical_cols = ['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']
categorical_cols1 = ['job','marital','education','housing','loan','poutcome']
OneHot_enc.fit(bank_data[categorical_cols])
X_train1_c = OneHot_enc.transform(X_train1[categorical_cols])
X_test1_c = OneHot_enc.transform(X_test1[categorical_cols])
cv_X_train1_c = OneHot_enc.transform(cv_X_train1[categorical_cols])
cv_X_test1_c = OneHot_enc.transform(cv_X_test1[categorical_cols]) 

OneHot_enc_1.fit(bank_data_1[categorical_cols1])
X_train1_1_c = OneHot_enc_1.transform(X_train1_1[categorical_cols1])
X_test1_1_c = OneHot_enc_1.transform(X_test1_1[categorical_cols1])
cv_X_train1_1_c = OneHot_enc_1.transform(cv_X_train1_1[categorical_cols1])
cv_X_test1_1_c = OneHot_enc_1.transform(cv_X_test1_1[categorical_cols1])

X_train1_cp = pd.DataFrame(X_train1_c, index=X_train1.index)
X_test1_cp = pd.DataFrame(X_test1_c, index=X_test1.index)
cv_X_train1_cp = pd.DataFrame(cv_X_train1_c, index=cv_X_train1.index)
cv_X_test1_cp = pd.DataFrame(cv_X_test1_c, index=cv_X_test1.index)

X_train1_1_cp = pd.DataFrame(X_train1_1_c, index=X_train1_1.index)
X_test1_1_cp = pd.DataFrame(X_test1_1_c, index=X_test1_1.index)
cv_X_train1_1_cp = pd.DataFrame(cv_X_train1_1_c, index=cv_X_train1_1.index)
cv_X_test1_1_cp = pd.DataFrame(cv_X_test1_1_c, index=cv_X_test1_1.index)

X_train1_ct = X_train1.drop(columns=categorical_cols)
X_test1_ct = X_test1.drop(columns=categorical_cols)
cv_X_train1_ct = cv_X_train1.drop(columns=categorical_cols)
cv_X_test1_ct = cv_X_test1.drop(columns=categorical_cols)

X_train1_1_ct = X_train1_1.drop(columns=categorical_cols1)
X_test1_1_ct = X_test1_1.drop(columns=categorical_cols1)
cv_X_train1_1_ct = cv_X_train1_1.drop(columns=categorical_cols1)
cv_X_test1_1_ct = cv_X_test1_1.drop(columns=categorical_cols1)

X_train1_ohe = pd.concat([X_train1_cp, X_train1_ct], axis=1)
X_test1_ohe = pd.concat([X_test1_cp, X_test1_ct], axis=1)
cv_X_train1_ohe = pd.concat([cv_X_train1_cp, cv_X_train1_ct], axis=1)
cv_X_test1_ohe = pd.concat([cv_X_test1_cp, cv_X_test1_ct], axis=1)

X_train1_1_ohe = pd.concat([X_train1_1_cp, X_train1_1_ct], axis=1)
X_test1_1_ohe = pd.concat([X_test1_1_cp, X_test1_1_ct], axis=1)
cv_X_train1_1_ohe = pd.concat([cv_X_train1_1_cp, cv_X_train1_1_ct], axis=1)
cv_X_test1_1_ohe = pd.concat([cv_X_test1_1_cp, cv_X_test1_1_ct], axis=1)

from sklearn.preprocessing import LabelEncoder
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()

#job-categoral
Label_enc.fit(bank_data['job'])
X_train.job = Label_enc.transform(X_train.job)
X_test.job = Label_enc.transform(X_test.job)
cv_X_train.job = Label_enc.transform(cv_X_train.job)
cv_X_test.job = Label_enc.transform(cv_X_test.job) 

Label_enc_1.fit(bank_data_1['job'])
X_train_1.job = Label_enc.transform(X_train_1.job)
X_test_1.job = Label_enc.transform(X_test_1.job)
cv_X_train_1.job = Label_enc.transform(cv_X_train_1.job)
cv_X_test_1.job = Label_enc.transform(cv_X_test_1.job)

#martial - categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['marital'])
X_train.marital = Label_enc.transform(X_train.marital)
X_test.marital = Label_enc.transform(X_test.marital)
cv_X_train.marital = Label_enc.transform(cv_X_train.marital)
cv_X_test.marital = Label_enc.transform(cv_X_test.marital) 

Label_enc_1.fit(bank_data_1['marital'])
X_train_1.marital = Label_enc.transform(X_train_1.marital)
X_test_1.marital = Label_enc.transform(X_test_1.marital)
cv_X_train_1.marital = Label_enc.transform(cv_X_train_1.marital)
cv_X_test_1.marital = Label_enc.transform(cv_X_test_1.marital)

#education - categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['education'])
X_train.education = Label_enc.transform(X_train.education)
X_test.education = Label_enc.transform(X_test.education)
cv_X_train.education = Label_enc.transform(cv_X_train.education)
cv_X_test.education = Label_enc.transform(cv_X_test.education) 

Label_enc_1.fit(bank_data_1['education'])
X_train_1.education = Label_enc.transform(X_train_1.education)
X_test_1.education = Label_enc.transform(X_test_1.education)
cv_X_train_1.education = Label_enc.transform(cv_X_train_1.education)
cv_X_test_1.education = Label_enc.transform(cv_X_test_1.education)

#default- categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['default'])
X_train.default = Label_enc.transform(X_train.default)
X_test.default = Label_enc.transform(X_test.default)
cv_X_train.default = Label_enc.transform(cv_X_train.default)
cv_X_test.default = Label_enc.transform(cv_X_test.default) 

#housing-categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['housing'])
X_train.housing = Label_enc.transform(X_train.housing)
X_test.housing = Label_enc.transform(X_test.housing) 
cv_X_train.housing = Label_enc.transform(cv_X_train.housing)
cv_X_test.housing = Label_enc.transform(cv_X_test.housing) 

Label_enc_1.fit(bank_data_1['housing'])
X_train_1.housing = Label_enc.transform(X_train_1.housing)
X_test_1.housing = Label_enc.transform(X_test_1.housing)
cv_X_train_1.housing = Label_enc.transform(cv_X_train_1.housing)
cv_X_test_1.housing = Label_enc.transform(cv_X_test_1.housing)

#loan-categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['loan'])
X_train.loan = Label_enc.transform(X_train.loan)
X_test.loan = Label_enc.transform(X_test.loan)
cv_X_train.loan = Label_enc.transform(cv_X_train.loan)
cv_X_test.loan = Label_enc.transform(cv_X_test.loan)  

Label_enc_1.fit(bank_data_1['loan'])
X_train_1.loan = Label_enc.transform(X_train_1.loan)
X_test_1.loan = Label_enc.transform(X_test_1.loan)
cv_X_train_1.loan = Label_enc.transform(cv_X_train_1.loan)
cv_X_test_1.loan = Label_enc.transform(cv_X_test_1.loan)

#contact-categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['contact'])
X_train.contact = Label_enc.transform(X_train.contact)
X_test.contact = Label_enc.transform(X_test.contact)
cv_X_train.contact = Label_enc.transform(cv_X_train.contact)
cv_X_test.contact = Label_enc.transform(cv_X_test.contact)

#month - categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['month'])
X_train.month = Label_enc.transform(X_train.month)
X_test.month = Label_enc.transform(X_test.month)
cv_X_train.month = Label_enc.transform(cv_X_train.month)
cv_X_test.month = Label_enc.transform(cv_X_test.month)

#day_of_week- categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['day_of_week'])
X_train.day_of_week = Label_enc.transform(X_train.day_of_week)
X_test.day_of_week = Label_enc.transform(X_test.day_of_week)
cv_X_train.day_of_week = Label_enc.transform(cv_X_train.day_of_week)
cv_X_test.day_of_week = Label_enc.transform(cv_X_test.day_of_week)

#poutcome - categoral
Label_enc = LabelEncoder()
Label_enc_1 = LabelEncoder()
Label_enc.fit(bank_data['poutcome'])
X_train.poutcome = Label_enc.transform(X_train.poutcome)
X_test.poutcome = Label_enc.transform(X_test.poutcome) 
cv_X_train.poutcome = Label_enc.transform(cv_X_train.poutcome)
cv_X_test.poutcome = Label_enc.transform(cv_X_test.poutcome) 

Label_enc_1.fit(bank_data_1['poutcome'])
X_train_1.poutcome = Label_enc.transform(X_train_1.poutcome)
X_test_1.poutcome = Label_enc.transform(X_test_1.poutcome)
cv_X_train_1.poutcome = Label_enc.transform(cv_X_train_1.poutcome)
cv_X_test_1.poutcome = Label_enc.transform(cv_X_test_1.poutcome)

X_train.head(5)

X_train_1.head(5)

#K-NN - All attributes - brute force - euclidean 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score
import math
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'euclidean')
  k_nn.fit(cv_X_train,cv_y_train)
  #prediction = k_nn.predict(X_test)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train)[:,1]
  train_auc.append(roc_auc_score(cv_y_train,prob_train))
  score_1 = k_nn.score(cv_X_test, cv_y_test)
  acc.append(score_1)

optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'euclidean')
k_nn.fit(cv_X_train,cv_y_train)
pred_test = k_nn.predict(X_test)
print(classification_report(y_test,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

#K-NN-reduced attributes-brute force - euclidean
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric='euclidean')
  k_nn.fit(cv_X_train_1,cv_y_train_1)
  #prediction = k_nn.predict(X_test)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test_1)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test_1,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train_1)[:,1]
  train_auc.append(roc_auc_score(cv_y_train_1,prob_train))
  score_1 = k_nn.score(cv_X_test_1, cv_y_test_1)
  acc.append(score_1)
optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'euclidean')
k_nn.fit(cv_X_train_1,cv_y_train_1)
pred_test = k_nn.predict(X_test_1)
print(classification_report(y_test_1,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

#K-NN-all atributes-brute force - cosine
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'cosine')
  k_nn.fit(cv_X_train_1,cv_y_train_1)
  #prediction = k_nn.predict(X_test)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test_1)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test_1,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train_1)[:,1]
  train_auc.append(roc_auc_score(cv_y_train_1,prob_train))
  score_1 = k_nn.score(cv_X_test_1, cv_y_test_1)
  acc.append(score_1)
optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)


#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'cosine')
k_nn.fit(cv_X_train_1,cv_y_train_1)
pred_test = k_nn.predict(X_test_1)
print(classification_report(y_test_1,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

#K-NN-reduced atributes-brute force - cosine
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'cosine')
  k_nn.fit(cv_X_train,cv_y_train)
  #prediction = k_nn.predict(X_test)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train)[:,1]
  train_auc.append(roc_auc_score(cv_y_train,prob_train))
  score_1 = k_nn.score(cv_X_test, cv_y_test)
  acc.append(score_1)
optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k, train_auc, label='AUC train')
x.plot(k, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'cosine')
k_nn.fit(cv_X_train,cv_y_train)
pred_test = k_nn.predict(X_test)
print(classification_report(y_test,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

scaler = StandardScaler()
X_train_sc = scaler.fit(X_train)
print(scaler.mean_)
X_test_sc = scaler.transform(X_test)
cv_X_train_sc = scaler.transform(cv_X_train)
cv_X_test_sc = scaler.transform(cv_X_test)

scaler1 = StandardScaler()
X_train_sc_1 = scaler1.fit(X_train_1)
print(scaler.mean_)
X_test_sc_1 = scaler1.transform(X_test_1)
cv_X_train_sc_1 = scaler1.transform(cv_X_train_1)
cv_X_test_sc_1 = scaler1.transform(cv_X_test_1)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score
import math
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'euclidean')
  k_nn.fit(cv_X_train_sc,cv_y_train)
  #prediction = k_nn.predict(X_test)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test_sc)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train_sc)[:,1]
  train_auc.append(roc_auc_score(cv_y_train,prob_train))
  score_1 = k_nn.score(cv_X_test_sc, cv_y_test)
  acc.append(score_1)

optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'euclidean')
k_nn.fit(cv_X_train_sc,cv_y_train)
pred_test = k_nn.predict(X_test_sc)
print(classification_report(y_test,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric='euclidean')
  k_nn.fit(cv_X_train_sc_1,cv_y_train_1)
  #prediction = k_nn.predict(X_test)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test_sc_1)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test_1,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train_sc_1)[:,1]
  train_auc.append(roc_auc_score(cv_y_train_1,prob_train))
  score_1 = k_nn.score(cv_X_test_sc_1, cv_y_test_1)
  acc.append(score_1)
optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'euclidean')
k_nn.fit(cv_X_train_sc_1,cv_y_train_1)
pred_test = k_nn.predict(X_test_sc_1)
print(classification_report(y_test_1,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

#K-NN-all atributes-brute force - cosine
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'cosine')
  k_nn.fit(cv_X_train_sc_1,cv_y_train_1)
  #prediction = k_nn.predict(X_test)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test_sc_1)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test_1,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train_sc_1)[:,1]
  train_auc.append(roc_auc_score(cv_y_train_1,prob_train))
  score_1 = k_nn.score(cv_X_test_sc_1, cv_y_test_1)
  acc.append(score_1)
optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)


#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'cosine')
k_nn.fit(cv_X_train_sc_1,cv_y_train_1)
pred_test = k_nn.predict(X_test_sc_1)
print(classification_report(y_test_1,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

#K-NN-reduced atributes-brute force - cosine
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'cosine')
  k_nn.fit(cv_X_train_sc,cv_y_train)
  #prediction = k_nn.predict(X_test)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test_sc)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train_sc)[:,1]
  train_auc.append(roc_auc_score(cv_y_train,prob_train))
  score_1 = k_nn.score(cv_X_test_sc, cv_y_test)
  acc.append(score_1)
optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k, train_auc, label='AUC train')
x.plot(k, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'cosine')
k_nn.fit(cv_X_train_sc,cv_y_train)
pred_test = k_nn.predict(X_test_sc)
print(classification_report(y_test,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

#K-NN - All attributes - brute force - euclidean 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score
import math
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'euclidean')
  k_nn.fit(cv_X_train1_ohe,cv_y_train)
  #prediction = k_nn.predict(X_test1_ohe)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train1_ohe, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test1_ohe)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train1_ohe)[:,1]
  train_auc.append(roc_auc_score(cv_y_train,prob_train))
  score_1 = k_nn.score(cv_X_test1_ohe, cv_y_test)
  acc.append(score_1)

optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'euclidean')
k_nn.fit(cv_X_train,cv_y_train)
pred_test = k_nn.predict(X_test)
print(classification_report(y_test,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
#K-NN - All attributes - brute force - euclidean 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score
import math
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'euclidean')
  k_nn.fit(cv_X_train1_1_ohe,cv_y_train)
  #prediction = k_nn.predict(X_test1_1_ohe)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train1_1_ohe, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test1_1_ohe)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train1_1_ohe)[:,1]
  train_auc.append(roc_auc_score(cv_y_train,prob_train))
  score_1 = k_nn.score(cv_X_test1_1_ohe, cv_y_test)
  acc.append(score_1)

optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'euclidean')
k_nn.fit(cv_X_train_1,cv_y_train)
pred_test = k_nn.predict(X_test_1)
print(classification_report(y_test,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

#K-NN - All attributes - brute force - cosine
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score
import math
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'cosine')
  k_nn.fit(cv_X_train1_1_ohe,cv_y_train)
  #prediction = k_nn.predict(X_test1_1_ohe)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train1_1_ohe, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test1_1_ohe)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train1_1_ohe)[:,1]
  train_auc.append(roc_auc_score(cv_y_train,prob_train))
  score_1 = k_nn.score(cv_X_test1_1_ohe, cv_y_test)
  acc.append(score_1)

optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'cosine')
k_nn.fit(cv_X_train_1,cv_y_train)
pred_test = k_nn.predict(X_test_1)
print(classification_report(y_test,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

#K-NN - All attributes - brute force - cosine
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score
import math
k = list(range(1,50,2))
train_auc = []
cv_auc = []
acc = []

for i in k:
  #print(i)
  k_nn = KNeighborsClassifier(n_neighbors = i,algorithm='brute',metric = 'cosine')
  k_nn.fit(cv_X_train1_ohe,cv_y_train)
  #prediction = k_nn.predict(X_test1_ohe)
  #cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  #scores = cross_val_score(k_nn, X_train1_ohe, y_train, cv=cv1)
  #print ('Cross validation', scores)
  #print(classification_report(y_test,prediction))
  prob_cv = k_nn.predict_proba(cv_X_test1_ohe)[:,1]
  cv_auc.append(roc_auc_score(cv_y_test,prob_cv))
  prob_train = k_nn.predict_proba(cv_X_train1_ohe)[:,1]
  train_auc.append(roc_auc_score(cv_y_train,prob_train))
  score_1 = k_nn.score(cv_X_test1_ohe, cv_y_test)
  acc.append(score_1)

optimal_k = k[cv_auc.index(max(cv_auc))]
k_1 = [math.log(x) for x in k]
value = int(np.argmax(acc))
print(value)

#plot auc vs alpha
x = plt.subplot( )
x.plot(k_1, train_auc, label='AUC train')
x.plot(k_1, cv_auc, label='AUC CV')
plt.title('AUC vs hyperparameter')
plt.xlabel('k')
plt.ylabel('AUC')
x.legend()
plt.show()

for j in range(len(acc)):
  print(j,acc[j])
print(k[value])

k_nn = KNeighborsClassifier(n_neighbors = k[value],algorithm='brute',metric = 'cosine')
k_nn.fit(cv_X_train,cv_y_train)
pred_test = k_nn.predict(X_test)
print(classification_report(y_test,pred_test))

plt.plot(k, acc)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

from sklearn.ensemble import RandomForestClassifier
classifiers_list = {
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "Naive Bayes : BernoulliNB": BernoulliNB()
}

classifiers_count = len(classifiers_list.keys())
df_results = pd.DataFrame(data=np.zeros(shape=(classifiers_count,5)), columns = ['classifier', 'Recall', 'F1', 'Precision', 'Accuracy'])

for c_name, classifier in classifiers_list.items():
  classifier.fit(cv_X_train1_ohe,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test1_ohe)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train1_ohe, cv_y_train, cv=cv1)
  print ('Classifier+OneHotEncoder', c_name)
  print ('Cross validation', scores)
  print(classification_report(y_test,prediction))

  classifier.fit(cv_X_train1_1_ohe,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test1_1_ohe)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train1_1_ohe, cv_y_train, cv=cv1)
  print ('Classifier+OneHotEncoder1', c_name)
  print ('Cross validation', scores)
  print(classification_report(y_test,prediction))

  classifier.fit(cv_X_train_1,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test_1)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train_1, cv_y_train, cv=cv1)
  print ('Classifier+Label_Encoder1+Scalar', c_name)
  print ('Cross validation', scores)
  print(classification_report(y_test,prediction))

  classifier.fit(cv_X_train,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train, cv_y_train, cv=cv1)
  print ('Classifier+Label_Encoder+Scalar', c_name)
  print ('Cross validation', scores)
  print(classification_report(y_test,prediction))

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
parameters = [{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},{'penalty':['none', 'elasticnet', 'l1', 'l2']},{'C':[0.001, 0.01, 0.1, 1, 10, 100]}]

grid_search = GridSearchCV(estimator =logreg,param_grid = parameters,scoring = 'accuracy',cv = 5,verbose=0)
grid_search1 = GridSearchCV(estimator =logreg,param_grid = parameters,scoring = 'accuracy',cv = 5,verbose=0)
grid_search_1 = GridSearchCV(estimator =logreg,param_grid = parameters,scoring = 'accuracy',cv = 5,verbose=0)
grid_search1_1 = GridSearchCV(estimator =logreg,param_grid = parameters,scoring = 'accuracy',cv = 5,verbose=0)

grid_search.fit(cv_X_train, cv_y_train)

grid_search1.fit(cv_X_train1_ohe, cv_y_train1)

grid_search_1.fit(cv_X_train_1, cv_y_train)

grid_search1_1.fit(cv_X_train1_1_ohe, cv_y_train1)

print("Tuned Hyperparameters :", grid_search.best_params_)
print("Accuracy :",grid_search.best_score_)

print("Tuned Hyperparameters :", grid_search1.best_params_)
print("Accuracy :",grid_search1.best_score_)

print("Tuned Hyperparameters :", grid_search_1.best_params_)
print("Accuracy :",grid_search_1.best_score_)

print("Tuned Hyperparameters :", grid_search1_1.best_params_)
print("Accuracy :",grid_search1_1.best_score_)

from sklearn.linear_model import LogisticRegression


classifiers_list = {
    "Logistic_Reg1": LogisticRegression(solver ='newton-cg'),
}

classifiers_count = len(classifiers_list.keys())
df_results = pd.DataFrame(data=np.zeros(shape=(classifiers_count,5)), columns = ['classifier', 'Recall', 'F1', 'Precision', 'Accuracy'])

for c_name, classifier in classifiers_list.items():
  classifier.fit(cv_X_train1_ohe,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test1_ohe)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train1_ohe, cv_y_train, cv=cv1)
  print ('Classifier+OneHotEncoder', c_name)
  print ('Cross validation', scores)
  print(classification_report(y_test,prediction))

  classifier.fit(cv_X_train1_1_ohe,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test1_1_ohe)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train1_1_ohe, cv_y_train, cv=cv1)
  print ('Classifier+OneHotEncoder1', c_name)
  print ('Cross validation', scores)
  print(classification_report(y_test,prediction))

  classifier.fit(cv_X_train_1,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test_1)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train_1, cv_y_train, cv=cv1)
  print ('Classifier+Label_Encoder1+Scalar', c_name)
  print ('Cross validation', scores)
  print(classification_report(y_test,prediction))

  classifier.fit(cv_X_train,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train, cv_y_train, cv=cv1)
  print ('Classifier+Label_Encoder+Scalar', c_name)
  print ('Cross validation', scores)
  print(classification_report(y_test,prediction))

dt = DecisionTreeClassifier()
parameters = [{"max_depth" : [None,1,2,3,4,5],'criterion':['gini','entropy'] }]

grid_search = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search1 = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search_1 = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search1_1 = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)

grid_search.fit(cv_X_train, cv_y_train)

grid_search1.fit(cv_X_train1_ohe, cv_y_train1)

grid_search_1.fit(cv_X_train_1, cv_y_train)

grid_search1_1.fit(cv_X_train1_1_ohe, cv_y_train1)

print("Tuned Hyperparameters :", grid_search.best_params_)
print("Accuracy :",grid_search.best_score_)
print("Tuned Hyperparameters :", grid_search1.best_params_)
print("Accuracy :",grid_search1.best_score_)
print("Tuned Hyperparameters :", grid_search_1.best_params_)
print("Accuracy :",grid_search_1.best_score_)
print("Tuned Hyperparameters :", grid_search1_1.best_params_)
print("Accuracy :",grid_search1_1.best_score_)

classifiers_list = {
    "Decision Tree1": DecisionTreeClassifier(criterion ='gini',max_depth = 3),
    "Decision Tree2": DecisionTreeClassifier(criterion ='gini',max_depth = 5),
    "Decision Tree3": DecisionTreeClassifier(criterion ='entropy',max_depth = None),
    "Decision Tree4": DecisionTreeClassifier(criterion ='entropy',max_depth = None)
}

for c_name, classifier in classifiers_list.items():
  classifier.fit(cv_X_train1_ohe,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test1_ohe)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train, cv_y_train, cv=cv1)
  scores1 = cross_val_score(classifier, cv_X_train1_ohe, cv_y_train1, cv=cv1)
  scores2 = cross_val_score(classifier, cv_X_train_1, cv_y_train, cv=cv1)
  scores3 = cross_val_score(classifier, cv_X_train1_1_ohe, cv_y_train1, cv=cv1)
  print ('Classifier+OneHotEncoder', c_name)
  print ('Cross validation', scores)
  print ('Cross validation', scores1)
  print ('Cross validation', scores2)
  print ('Cross validation', scores3)
  #print(classification_report(y_test,prediction))
  #classifier.fit(cv_X_train, cv_y_train)
  #classifier.fit(cv_X_train1_ohe, cv_y_train1)
  #classifier.fit(cv_X_train_1, cv_y_train)
  #classifier.fit(cv_X_train1_1_ohe, cv_y_train1)

from sklearn.ensemble import RandomForestClassifier
dt = RandomForestClassifier()
parameters = [{"max_depth" : [None,1,2,3,4,5],'criterion':['gini','entropy'] }]

grid_search = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search1 = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search_1 = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search1_1 = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)

grid_search.fit(cv_X_train, cv_y_train)

grid_search1.fit(cv_X_train1_ohe, cv_y_train1)

grid_search_1.fit(cv_X_train_1, cv_y_train)

grid_search1_1.fit(cv_X_train1_1_ohe, cv_y_train1)

print("Tuned Hyperparameters :", grid_search.best_params_)
print("F1_Macro :",grid_search.best_score_)
print("Tuned Hyperparameters :", grid_search1.best_params_)
print("F1_Macro :",grid_search1.best_score_)
print("Tuned Hyperparameters :", grid_search_1.best_params_)
print("F1_Macro :",grid_search_1.best_score_)
print("Tuned Hyperparameters :", grid_search1_1.best_params_)
print("F1_Macro :",grid_search1_1.best_score_)

classifiers_list = {
    "Random Forest1": RandomForestClassifier(criterion ='gini',max_depth = 3),
    "Random Forest2": RandomForestClassifier(criterion ='gini',max_depth = 5),
    "Random Forest3": RandomForestClassifier(criterion ='entropy',max_depth = None),
    "Random Forest4": RandomForestClassifier(criterion ='entropy',max_depth = None)
}

for c_name, classifier in classifiers_list.items():
  classifier.fit(cv_X_train1_ohe,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test1_ohe)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train, cv_y_train, cv=cv1)
  scores1 = cross_val_score(classifier, cv_X_train1_ohe, cv_y_train1, cv=cv1)
  scores2 = cross_val_score(classifier, cv_X_train_1, cv_y_train, cv=cv1)
  scores3 = cross_val_score(classifier, cv_X_train1_1_ohe, cv_y_train1, cv=cv1)
  print ('Classifier+OneHotEncoder', c_name)
  print ('Cross validation', scores)
  print ('Cross validation', scores1)
  print ('Cross validation', scores2)
  print ('Cross validation', scores3)
  #print(classification_report(y_test,prediction))
  #classifier.fit(cv_X_train, cv_y_train)
  #classifier.fit(cv_X_train1_ohe, cv_y_train1)
  #classifier.fit(cv_X_train_1, cv_y_train)
  #classifier.fit(cv_X_train1_1_ohe, cv_y_train1)

from sklearn.naive_bayes import BernoulliNB
nb = BernoulliNB()
parameters = [{'alpha':[0.00001, 0.0001, 0.001, 0.1, 1, 10, 100,1000]}]

grid_search = GridSearchCV(estimator =nb,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search1 = GridSearchCV(estimator =nb,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search_1 = GridSearchCV(estimator =nb,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)
grid_search1_1 = GridSearchCV(estimator =nb,param_grid = parameters,scoring = 'f1_macro',cv = 5,verbose=0)

grid_search.fit(cv_X_train, cv_y_train)

grid_search1.fit(cv_X_train1_ohe, cv_y_train1)

grid_search_1.fit(cv_X_train_1, cv_y_train)

grid_search1_1.fit(cv_X_train1_1_ohe, cv_y_train1)

print("Tuned Hyperparameters :", grid_search.best_params_)
print("F1_Macro :",grid_search.best_score_)
print("Tuned Hyperparameters :", grid_search1.best_params_)
print("F1_Macro :",grid_search1.best_score_)
print("Tuned Hyperparameters :", grid_search_1.best_params_)
print("F1_Macro :",grid_search_1.best_score_)
print("Tuned Hyperparameters :", grid_search1_1.best_params_)
print("F1_Macro :",grid_search1_1.best_score_)

classifiers_list = {
    "Naive Bayes - Bernoulli1 ": BernoulliNB(alpha = 1e-05),
    "Naive Bayes - Bernoulli2 ": BernoulliNB(alpha = 1),
    "Naive Bayes - Bernoulli3 ": BernoulliNB(alpha = 1e-05),
    "Naive Bayes - Bernoulli4 ": BernoulliNB(alpha = 100)
}

for c_name, classifier in classifiers_list.items():
  classifier.fit(cv_X_train1_ohe,cv_y_train)
  prediction = []
  prediction = classifier.predict(X_test1_ohe)
  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  scores = cross_val_score(classifier, cv_X_train, cv_y_train, cv=cv1)
  scores1 = cross_val_score(classifier, cv_X_train1_ohe, cv_y_train1, cv=cv1)
  scores2 = cross_val_score(classifier, cv_X_train_1, cv_y_train, cv=cv1)
  scores3 = cross_val_score(classifier, cv_X_train1_1_ohe, cv_y_train1, cv=cv1)
  print ('Classifier+OneHotEncoder', c_name)
  print ('Cross validation', scores)
  print ('Cross validation', scores1)
  print ('Cross validation', scores2)
  print ('Cross validation', scores3)
  #print(classification_report(y_test,prediction))
  #classifier.fit(cv_X_train, cv_y_train)
  #classifier.fit(cv_X_train1_ohe, cv_y_train1)
  #classifier.fit(cv_X_train_1, cv_y_train)
  #classifier.fit(cv_X_train1_1_ohe, cv_y_train1)