{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
      ],
      "metadata": {
        "id": "6JmUByES0t2a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colnames=['lettr', 'x-box', 'y-box', 'width','high','onpix','x-bar','y-bar','x2bar','y2bar','xybar','x2ybr','xy2br','x-ege','xegvy','y-ege','yegvx'] \n",
        "print(len(colnames))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONEoBGTW080-",
        "outputId": "2c157fbb-cbd9-43b5-f44b-422002586696"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train=pd.read_csv('/content/drive/MyDrive/train.csv',sep=\",\",names=colnames, header=None)\n",
        "df_Test=pd.read_csv('/content/drive/MyDrive/test.csv',sep=\",\",names=colnames, header=None)"
      ],
      "metadata": {
        "id": "8bJZuANf2Ggx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6kINuuVv1PYh",
        "outputId": "e3ee599e-daa3-4638-ddb3-a0da9270c7e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  lettr  x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
              "0     T      2      8      3     5      1      8     13      0      6      6   \n",
              "1     I      5     12      3     7      2     10      5      5      4     13   \n",
              "2     D      4     11      6     8      6     10      6      2      6     10   \n",
              "3     N      7     11      6     6      3      5      9      4      6      4   \n",
              "4     G      2      1      3     1      1      8      6      6      6      6   \n",
              "\n",
              "   x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
              "0     10      8      0      8      0      8  \n",
              "1      3      9      2      8      4     10  \n",
              "2      3      7      3      7      3      9  \n",
              "3      4     10      6     10      2      8  \n",
              "4      5      9      1      7      5     10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9f9d7a6-580a-4fa0-8715-c7338e370c29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lettr</th>\n",
              "      <th>x-box</th>\n",
              "      <th>y-box</th>\n",
              "      <th>width</th>\n",
              "      <th>high</th>\n",
              "      <th>onpix</th>\n",
              "      <th>x-bar</th>\n",
              "      <th>y-bar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybr</th>\n",
              "      <th>xy2br</th>\n",
              "      <th>x-ege</th>\n",
              "      <th>xegvy</th>\n",
              "      <th>y-ege</th>\n",
              "      <th>yegvx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>G</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9f9d7a6-580a-4fa0-8715-c7338e370c29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9f9d7a6-580a-4fa0-8715-c7338e370c29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9f9d7a6-580a-4fa0-8715-c7338e370c29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "wS_E8sNm2Vkj",
        "outputId": "bf745b4f-baec-4bcf-fe56-3e9ba424c06a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              x-box         y-box         width          high         onpix  \\\n",
              "count  16000.000000  16000.000000  16000.000000  16000.000000  16000.000000   \n",
              "mean       4.020187      7.028937      5.117312      5.365875      3.500125   \n",
              "std        1.908503      3.303923      2.003260      2.262621      2.192271   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        3.000000      5.000000      4.000000      4.000000      2.000000   \n",
              "50%        4.000000      7.000000      5.000000      6.000000      3.000000   \n",
              "75%        5.000000      9.000000      6.000000      7.000000      5.000000   \n",
              "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
              "\n",
              "              x-bar         y-bar         x2bar         y2bar         xybar  \\\n",
              "count  16000.000000  16000.000000  16000.000000  16000.000000  16000.000000   \n",
              "mean       6.892625      7.512437      4.627313      5.170375      8.286625   \n",
              "std        2.029527      2.333867      2.711573      2.384864      2.485706   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
              "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
              "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
              "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
              "\n",
              "              x2ybr         xy2br         x-ege         xegvy         y-ege  \\\n",
              "count  16000.000000  16000.000000  16000.000000  16000.000000  16000.000000   \n",
              "mean       6.471250      7.927125      3.048750      8.343937      3.682000   \n",
              "std        2.642061      2.071976      2.342481      1.550055      2.571389   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        5.000000      7.000000      1.000000      8.000000      2.000000   \n",
              "50%        6.000000      8.000000      3.000000      8.000000      3.000000   \n",
              "75%        8.000000      9.000000      4.000000      9.000000      5.000000   \n",
              "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
              "\n",
              "              yegvx  \n",
              "count  16000.000000  \n",
              "mean       7.796250  \n",
              "std        1.603402  \n",
              "min        1.000000  \n",
              "25%        7.000000  \n",
              "50%        8.000000  \n",
              "75%        8.000000  \n",
              "max       15.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9f3ce80-ecbc-4655-9b87-11a622bdd859\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x-box</th>\n",
              "      <th>y-box</th>\n",
              "      <th>width</th>\n",
              "      <th>high</th>\n",
              "      <th>onpix</th>\n",
              "      <th>x-bar</th>\n",
              "      <th>y-bar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybr</th>\n",
              "      <th>xy2br</th>\n",
              "      <th>x-ege</th>\n",
              "      <th>xegvy</th>\n",
              "      <th>y-ege</th>\n",
              "      <th>yegvx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "      <td>16000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.020187</td>\n",
              "      <td>7.028937</td>\n",
              "      <td>5.117312</td>\n",
              "      <td>5.365875</td>\n",
              "      <td>3.500125</td>\n",
              "      <td>6.892625</td>\n",
              "      <td>7.512437</td>\n",
              "      <td>4.627313</td>\n",
              "      <td>5.170375</td>\n",
              "      <td>8.286625</td>\n",
              "      <td>6.471250</td>\n",
              "      <td>7.927125</td>\n",
              "      <td>3.048750</td>\n",
              "      <td>8.343937</td>\n",
              "      <td>3.682000</td>\n",
              "      <td>7.796250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.908503</td>\n",
              "      <td>3.303923</td>\n",
              "      <td>2.003260</td>\n",
              "      <td>2.262621</td>\n",
              "      <td>2.192271</td>\n",
              "      <td>2.029527</td>\n",
              "      <td>2.333867</td>\n",
              "      <td>2.711573</td>\n",
              "      <td>2.384864</td>\n",
              "      <td>2.485706</td>\n",
              "      <td>2.642061</td>\n",
              "      <td>2.071976</td>\n",
              "      <td>2.342481</td>\n",
              "      <td>1.550055</td>\n",
              "      <td>2.571389</td>\n",
              "      <td>1.603402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9f3ce80-ecbc-4655-9b87-11a622bdd859')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9f3ce80-ecbc-4655-9b87-11a622bdd859 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9f3ce80-ecbc-4655-9b87-11a622bdd859');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Test.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "PPoWmFbm8fGs",
        "outputId": "f83c416e-66e3-4c21-c951-c05d9a2fb064"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             x-box        y-box        width         high        onpix  \\\n",
              "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
              "mean      4.037000     7.061750     5.140000     5.398750     3.528750   \n",
              "std       1.932114     3.307366     2.059359     2.256551     2.183315   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       3.000000     5.000000     4.000000     4.000000     2.000000   \n",
              "50%       4.000000     7.000000     5.000000     6.000000     3.000000   \n",
              "75%       5.000000     9.000000     6.000000     7.000000     5.000000   \n",
              "max      14.000000    15.000000    14.000000    14.000000    15.000000   \n",
              "\n",
              "            x-bar        y-bar       x2bar        y2bar       xybar  \\\n",
              "count  4000.00000  4000.000000  4000.00000  4000.000000  4000.00000   \n",
              "mean      6.91750     7.452500     4.63375     5.211750     8.26375   \n",
              "std       2.01214     2.290645     2.65337     2.364595     2.49975   \n",
              "min       0.00000     0.000000     0.00000     0.000000     0.00000   \n",
              "25%       6.00000     6.000000     3.00000     4.000000     7.00000   \n",
              "50%       7.00000     7.000000     4.00000     5.000000     7.00000   \n",
              "75%       8.00000     8.000000     6.00000     7.000000    10.00000   \n",
              "max      15.00000    15.000000    15.00000    15.000000    15.00000   \n",
              "\n",
              "             x2ybr        xy2br        x-ege        xegvy        y-ege  \\\n",
              "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
              "mean      6.385000     7.936500     3.035500     8.318500     3.730750   \n",
              "std       2.585816     2.115085     2.292609     1.533345     2.549682   \n",
              "min       0.000000     2.000000     0.000000     1.000000     0.000000   \n",
              "25%       5.000000     7.000000     2.000000     8.000000     2.000000   \n",
              "50%       6.000000     8.000000     3.000000     8.000000     4.000000   \n",
              "75%       8.000000     9.000000     4.000000     9.000000     5.000000   \n",
              "max      15.000000    15.000000    15.000000    14.000000    15.000000   \n",
              "\n",
              "            yegvx  \n",
              "count  4000.00000  \n",
              "mean      7.82100  \n",
              "std       1.67262  \n",
              "min       0.00000  \n",
              "25%       7.00000  \n",
              "50%       8.00000  \n",
              "75%       9.00000  \n",
              "max      15.00000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c38f6411-9758-4562-a158-713870b2bea3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x-box</th>\n",
              "      <th>y-box</th>\n",
              "      <th>width</th>\n",
              "      <th>high</th>\n",
              "      <th>onpix</th>\n",
              "      <th>x-bar</th>\n",
              "      <th>y-bar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybr</th>\n",
              "      <th>xy2br</th>\n",
              "      <th>x-ege</th>\n",
              "      <th>xegvy</th>\n",
              "      <th>y-ege</th>\n",
              "      <th>yegvx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.00000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.00000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.00000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.037000</td>\n",
              "      <td>7.061750</td>\n",
              "      <td>5.140000</td>\n",
              "      <td>5.398750</td>\n",
              "      <td>3.528750</td>\n",
              "      <td>6.91750</td>\n",
              "      <td>7.452500</td>\n",
              "      <td>4.63375</td>\n",
              "      <td>5.211750</td>\n",
              "      <td>8.26375</td>\n",
              "      <td>6.385000</td>\n",
              "      <td>7.936500</td>\n",
              "      <td>3.035500</td>\n",
              "      <td>8.318500</td>\n",
              "      <td>3.730750</td>\n",
              "      <td>7.82100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.932114</td>\n",
              "      <td>3.307366</td>\n",
              "      <td>2.059359</td>\n",
              "      <td>2.256551</td>\n",
              "      <td>2.183315</td>\n",
              "      <td>2.01214</td>\n",
              "      <td>2.290645</td>\n",
              "      <td>2.65337</td>\n",
              "      <td>2.364595</td>\n",
              "      <td>2.49975</td>\n",
              "      <td>2.585816</td>\n",
              "      <td>2.115085</td>\n",
              "      <td>2.292609</td>\n",
              "      <td>1.533345</td>\n",
              "      <td>2.549682</td>\n",
              "      <td>1.67262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.00000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.00000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.00000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38f6411-9758-4562-a158-713870b2bea3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c38f6411-9758-4562-a158-713870b2bea3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c38f6411-9758-4562-a158-713870b2bea3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pandas-profiling==3.4.0\n",
        "#from pandas_profiling import ProfileReport\n",
        "#profile = ProfileReport(df)"
      ],
      "metadata": {
        "id": "M4GVbw0_2e0X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#profile.to_file(output_file=\"pandas_profiling1.html\")"
      ],
      "metadata": {
        "id": "VKoLpl8C2wjM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train['lettr'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c-i7K5L3v1O",
        "outputId": "3f074b66-2f1d-4d0d-af04-26d41656326c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    648\n",
              "T    645\n",
              "U    645\n",
              "Y    641\n",
              "D    638\n",
              "P    635\n",
              "A    633\n",
              "B    630\n",
              "X    628\n",
              "V    628\n",
              "F    622\n",
              "N    617\n",
              "E    616\n",
              "Q    615\n",
              "O    614\n",
              "W    613\n",
              "G    609\n",
              "L    604\n",
              "J    599\n",
              "R    597\n",
              "C    594\n",
              "K    593\n",
              "I    590\n",
              "S    587\n",
              "H    583\n",
              "Z    576\n",
              "Name: lettr, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train['lettr'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Vt0QJfAe9kMu",
        "outputId": "d3e515ac-7678-438b-b624-a04c3f8e0473"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd935dda60>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Test['lettr'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Vn4rpUqd-Kqg",
        "outputId": "62b68743-58cd-4c43-e50a-dc447c6e9c48"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd934be820>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Test['lettr'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLpdlpuE8nsx",
        "outputId": "f15ce4c2-6c02-4d7c-93d2-e9ac4ad47aab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "U    168\n",
              "Q    168\n",
              "P    168\n",
              "D    167\n",
              "N    166\n",
              "I    165\n",
              "G    164\n",
              "S    161\n",
              "R    161\n",
              "X    159\n",
              "Z    158\n",
              "L    157\n",
              "A    156\n",
              "F    153\n",
              "E    152\n",
              "H    151\n",
              "T    151\n",
              "J    148\n",
              "K    146\n",
              "Y    145\n",
              "M    144\n",
              "C    142\n",
              "O    139\n",
              "W    139\n",
              "B    136\n",
              "V    136\n",
              "Name: lettr, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5T8erkd4FQ2",
        "outputId": "d2e2d6d8-ba8d-41c7-c061-07b694e9d874"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U5408Wd8rc2",
        "outputId": "86050686-757b-4707-82da-138e61cb443f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQt_tk5M4G0q",
        "outputId": "fe8f039a-e8a3-4461-de0b-cff5464b6f2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16000 entries, 0 to 15999\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   lettr   16000 non-null  object\n",
            " 1   x-box   16000 non-null  int64 \n",
            " 2   y-box   16000 non-null  int64 \n",
            " 3   width   16000 non-null  int64 \n",
            " 4   high    16000 non-null  int64 \n",
            " 5   onpix   16000 non-null  int64 \n",
            " 6   x-bar   16000 non-null  int64 \n",
            " 7   y-bar   16000 non-null  int64 \n",
            " 8   x2bar   16000 non-null  int64 \n",
            " 9   y2bar   16000 non-null  int64 \n",
            " 10  xybar   16000 non-null  int64 \n",
            " 11  x2ybr   16000 non-null  int64 \n",
            " 12  xy2br   16000 non-null  int64 \n",
            " 13  x-ege   16000 non-null  int64 \n",
            " 14  xegvy   16000 non-null  int64 \n",
            " 15  y-ege   16000 non-null  int64 \n",
            " 16  yegvx   16000 non-null  int64 \n",
            "dtypes: int64(16), object(1)\n",
            "memory usage: 2.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "citnFOBS8wGS",
        "outputId": "b8c40dbb-60c6-4184-f0f7-2468d14ef357"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4000 entries, 0 to 3999\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   lettr   4000 non-null   object\n",
            " 1   x-box   4000 non-null   int64 \n",
            " 2   y-box   4000 non-null   int64 \n",
            " 3   width   4000 non-null   int64 \n",
            " 4   high    4000 non-null   int64 \n",
            " 5   onpix   4000 non-null   int64 \n",
            " 6   x-bar   4000 non-null   int64 \n",
            " 7   y-bar   4000 non-null   int64 \n",
            " 8   x2bar   4000 non-null   int64 \n",
            " 9   y2bar   4000 non-null   int64 \n",
            " 10  xybar   4000 non-null   int64 \n",
            " 11  x2ybr   4000 non-null   int64 \n",
            " 12  xy2br   4000 non-null   int64 \n",
            " 13  x-ege   4000 non-null   int64 \n",
            " 14  xegvy   4000 non-null   int64 \n",
            " 15  y-ege   4000 non-null   int64 \n",
            " 16  yegvx   4000 non-null   int64 \n",
            "dtypes: int64(16), object(1)\n",
            "memory usage: 531.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX1LEp8z4L9U",
        "outputId": "c19b6eac-a3af-418b-fab1-b67e6a6a17de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lettr    0\n",
              "x-box    0\n",
              "y-box    0\n",
              "width    0\n",
              "high     0\n",
              "onpix    0\n",
              "x-bar    0\n",
              "y-bar    0\n",
              "x2bar    0\n",
              "y2bar    0\n",
              "xybar    0\n",
              "x2ybr    0\n",
              "xy2br    0\n",
              "x-ege    0\n",
              "xegvy    0\n",
              "y-ege    0\n",
              "yegvx    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk4Z8ib381EY",
        "outputId": "c059a746-0a90-4fbc-b6eb-4474159ca3c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lettr    0\n",
              "x-box    0\n",
              "y-box    0\n",
              "width    0\n",
              "high     0\n",
              "onpix    0\n",
              "x-bar    0\n",
              "y-bar    0\n",
              "x2bar    0\n",
              "y2bar    0\n",
              "xybar    0\n",
              "x2ybr    0\n",
              "xy2br    0\n",
              "x-ege    0\n",
              "xegvy    0\n",
              "y-ege    0\n",
              "yegvx    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_Train = df_Train['lettr']\n",
        "y_Train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4erMnVj39E2F",
        "outputId": "679266f4-e2d1-4b17-8d50-e8c0de94bfdf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    T\n",
              "1    I\n",
              "2    D\n",
              "3    N\n",
              "4    G\n",
              "Name: lettr, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_Test = df_Test['lettr']\n",
        "y_Test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApGpK72u9g0I",
        "outputId": "b1a92d14-2638-441a-9212-cfc42229077a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    U\n",
              "1    N\n",
              "2    V\n",
              "3    I\n",
              "4    N\n",
              "Name: lettr, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Train.drop(['lettr'],axis=1,inplace = True)\n",
        "df_Test.drop(['lettr'],axis=1,inplace = True)"
      ],
      "metadata": {
        "id": "PjRIZWBI9wka"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_Train.shape)\n",
        "print(df_Test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9VV3xzQ-E01",
        "outputId": "0e573486-1032-4aec-d4ec-7d94b3e6be39"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 16)\n",
            "(4000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_Train, y_Train, test_size=0.2, random_state=0)\n",
        "cv_X_train, cv_X_test, cv_y_train, cv_y_test = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "kVNsVUx686CJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv_X_train.shape)\n",
        "print(cv_X_test.shape)\n",
        "print(cv_y_train.shape)\n",
        "print(cv_y_test.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RcC2hp--McU",
        "outputId": "f8855a1b-8c25-4b2d-f396-5b948ad534dc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10240, 16)\n",
            "(2560, 16)\n",
            "(10240,)\n",
            "(2560,)\n",
            "(3200, 16)\n",
            "(3200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Label_enc = LabelEncoder()\n",
        "\n",
        "Label_enc.fit(y_Train)\n",
        "y_Train = Label_enc.transform(y_Train)\n",
        "y_train = Label_enc.transform(y_train)\n",
        "y_test = Label_enc.transform(y_test)\n",
        "cv_y_train = Label_enc.transform(cv_y_train)\n",
        "cv_y_test = Label_enc.transform(cv_y_test)\n",
        "y_Test = Label_enc.transform(y_Test) "
      ],
      "metadata": {
        "id": "5SORAUZ24R6R"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_Test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QPm0AtZ_ql2",
        "outputId": "e30f7621-6b82-4da4-aa08-1c2f8bd26c8f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20 13 21 ... 19 18  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df_Train)\n",
        "\n",
        "X_Train_mm = scaler.transform(df_Train)\n",
        "X_train_mm = scaler.transform(X_train)\n",
        "X_test_mm = scaler.transform(X_test)\n",
        "cv_X_train_mm = scaler.transform(cv_X_train)\n",
        "cv_X_test_mm = scaler.transform(cv_X_test)\n",
        "X_Test_mm = scaler.transform(df_Test)"
      ],
      "metadata": {
        "id": "n8e_HMZMA2yA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_mm[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBIHUdIMOeCT",
        "outputId": "e956f825-92c8-4c85-d88d-306559c55d4c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.53333333 0.8        0.66666667 0.46666667 0.33333333 0.6\n",
            " 0.26666667 0.2        0.13333333 0.66666667 0.13333333 0.6\n",
            " 0.66666667 0.06666667 0.06666667 0.5       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train_mm[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFPKygV0O6Nm",
        "outputId": "9ff5483f-b579-4072-d94c-9d90750155cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "nnmodel = MLPClassifier(random_state=0)\n",
        "\n",
        "nnmodel.fit(cv_X_train_mm,cv_y_train)\n",
        "y_pred=nnmodel.predict(cv_X_test_mm)\n",
        "print(classification_report(y_pred,cv_y_test))\n",
        "cm=confusion_matrix(y_pred,cv_y_test)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Z5Do63TGZ8",
        "outputId": "897fd51c-cc7e-4157-f3d5-b187ed970380"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.88      0.90        98\n",
            "           1       0.88      0.66      0.75       143\n",
            "           2       0.84      0.94      0.89        71\n",
            "           3       0.81      0.85      0.83       113\n",
            "           4       0.86      0.88      0.87        96\n",
            "           5       0.85      0.85      0.85       110\n",
            "           6       0.70      0.68      0.69        77\n",
            "           7       0.70      0.76      0.73        84\n",
            "           8       0.85      0.93      0.89        83\n",
            "           9       0.84      0.88      0.86       101\n",
            "          10       0.81      0.80      0.81       102\n",
            "          11       0.86      0.87      0.87        93\n",
            "          12       0.90      0.94      0.92        97\n",
            "          13       0.94      0.91      0.93       112\n",
            "          14       0.79      0.71      0.75        93\n",
            "          15       0.92      0.89      0.91       118\n",
            "          16       0.72      0.85      0.78        86\n",
            "          17       0.69      0.80      0.74        93\n",
            "          18       0.66      0.75      0.70        79\n",
            "          19       0.91      0.82      0.86       119\n",
            "          20       0.91      0.86      0.88       107\n",
            "          21       0.92      0.91      0.91       121\n",
            "          22       0.87      0.83      0.85        88\n",
            "          23       0.80      0.80      0.80        95\n",
            "          24       0.83      0.91      0.87        91\n",
            "          25       0.87      0.82      0.85        90\n",
            "\n",
            "    accuracy                           0.84      2560\n",
            "   macro avg       0.83      0.84      0.83      2560\n",
            "weighted avg       0.84      0.84      0.84      2560\n",
            "\n",
            "[[ 86   0   0   0   0   0   0   0   0   3   0   0   0   0   4   0   1   1\n",
            "    0   0   1   1   0   1   0   0]\n",
            " [  0  94   0   8   3   2   1   1   0   0   0   0   2   0   1   0   3  12\n",
            "    9   2   0   2   2   1   0   0]\n",
            " [  0   0  67   0   0   0   1   0   0   0   2   0   0   0   0   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   1  96   0   2   1   2   1   0   0   0   1   1   1   0   0   3\n",
            "    1   1   0   0   0   2   0   0]\n",
            " [  0   0   2   0  84   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    4   0   0   0   0   2   0   3]\n",
            " [  0   0   1   0   0  93   1   0   4   1   0   0   0   1   0   3   0   0\n",
            "    4   0   0   0   0   1   1   0]\n",
            " [  0   2   0   0   7   4  52   0   0   0   0   2   0   0   0   3   3   0\n",
            "    1   1   0   2   0   0   0   0]\n",
            " [  2   1   0   0   0   1   0  64   0   2   4   2   1   0   0   0   0   3\n",
            "    0   1   1   1   0   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0  77   4   0   0   0   0   0   1   0   0\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   1   0   0   0   4   1  89   0   0   0   0   0   0   0   0\n",
            "    1   0   0   0   0   1   2   2]\n",
            " [  1   0   3   0   1   0   1   4   0   0  82   1   0   0   0   0   0   7\n",
            "    0   0   0   0   0   2   0   0]\n",
            " [  0   0   1   0   0   0   1   0   0   0   0  81   0   0   0   0   3   2\n",
            "    3   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  91   1   2   0   0   0\n",
            "    0   0   3   0   0   0   0   0]\n",
            " [  0   1   0   2   0   1   0   3   0   0   0   0   3 102   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   2   2   5   0   0   2   0   0   0   0   0   0   2  66   1   5   3\n",
            "    0   0   2   0   3   0   0   0]\n",
            " [  0   2   0   1   0   3   5   0   1   0   0   0   0   0   0 105   0   0\n",
            "    0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0   2   0   1   3   0   0   0   1   0   0   1   0  73   1\n",
            "    1   0   0   0   0   1   2   0]\n",
            " [  0   3   0   0   0   0   3   8   0   0   2   0   1   0   0   0   1  74\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  2   1   0   0   0   1   2   0   4   3   0   1   0   0   0   0   2   0\n",
            "   59   0   0   0   0   0   0   4]\n",
            " [  1   0   2   1   1   3   0   0   0   0   1   3   0   0   0   0   0   2\n",
            "    0  97   0   0   0   2   5   1]\n",
            " [  1   0   1   0   0   0   0   0   0   0   3   0   2   1   0   0   0   0\n",
            "    0   1  92   0   3   1   2   0]\n",
            " [  0   0   0   0   0   0   2   2   0   0   1   0   0   0   0   0   0   0\n",
            "    1   1   0 110   3   0   1   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   9   0   0   0\n",
            "    0   0   2   2  73   0   1   0]\n",
            " [  0   0   0   1   0   0   0   0   2   3   6   3   0   0   0   0   1   0\n",
            "    0   1   0   0   0  76   2   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0\n",
            "    2   2   0   1   0   0  83   0]\n",
            " [  0   0   0   3   0   0   0   0   1   1   0   0   0   0   0   0   6   0\n",
            "    3   0   0   0   0   2   0  74]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler1 = StandardScaler()\n",
        "scaler1.fit(df_Train)\n",
        "\n",
        "X_Train_sc = scaler1.transform(df_Train)\n",
        "X_train_sc = scaler1.transform(X_train)\n",
        "X_test_sc = scaler1.transform(X_test)\n",
        "cv_X_train_sc = scaler1.transform(cv_X_train)\n",
        "cv_X_test_sc = scaler1.transform(cv_X_test)\n",
        "X_Test_sc = scaler1.transform(df_Test)"
      ],
      "metadata": {
        "id": "Aqexqqs074AY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#parameters = {'hidden_layer_sizes': [(100,),(100,10),(100,20),(100,30),(250,300)],'activation': ['tanh', 'relu','logistic'],'solver': ['sgd', 'adam','lbfgs'],'alpha': 10.0 ** -np.arange(1, 5),'learning_rate': ['constant','adaptive']}\n",
        "#clf = GridSearchCV(MLPClassifier(),param_grid = parameters, scoring = 'accuracy',cv = 5, n_jobs=-1)\n",
        "#clf.fit(cv_X_train_mm,cv_y_train)\n"
      ],
      "metadata": {
        "id": "HVzgjoibT8Zs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
        "#print(\"Accuracy :\",clf.best_score_)"
      ],
      "metadata": {
        "id": "AjfcOdwRUYFe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MPL1 = MLPClassifier(activation= 'tanh', alpha = 0.1, hidden_layer_sizes = (100,), learning_rate = 'constant', solver = 'lbfgs')"
      ],
      "metadata": {
        "id": "4_A5LA9ARTIu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MPL1.fit(cv_X_train_mm,cv_y_train)\n",
        "y_pred=nnmodel.predict(cv_X_test_mm)\n",
        "print(classification_report(y_pred,cv_y_test))\n",
        "cm=confusion_matrix(y_pred,cv_y_test)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt3IzwTURlIC",
        "outputId": "6679b00c-dfdf-447b-da0c-0193d6e20652"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.88      0.90        98\n",
            "           1       0.88      0.66      0.75       143\n",
            "           2       0.84      0.94      0.89        71\n",
            "           3       0.81      0.85      0.83       113\n",
            "           4       0.86      0.88      0.87        96\n",
            "           5       0.85      0.85      0.85       110\n",
            "           6       0.70      0.68      0.69        77\n",
            "           7       0.70      0.76      0.73        84\n",
            "           8       0.85      0.93      0.89        83\n",
            "           9       0.84      0.88      0.86       101\n",
            "          10       0.81      0.80      0.81       102\n",
            "          11       0.86      0.87      0.87        93\n",
            "          12       0.90      0.94      0.92        97\n",
            "          13       0.94      0.91      0.93       112\n",
            "          14       0.79      0.71      0.75        93\n",
            "          15       0.92      0.89      0.91       118\n",
            "          16       0.72      0.85      0.78        86\n",
            "          17       0.69      0.80      0.74        93\n",
            "          18       0.66      0.75      0.70        79\n",
            "          19       0.91      0.82      0.86       119\n",
            "          20       0.91      0.86      0.88       107\n",
            "          21       0.92      0.91      0.91       121\n",
            "          22       0.87      0.83      0.85        88\n",
            "          23       0.80      0.80      0.80        95\n",
            "          24       0.83      0.91      0.87        91\n",
            "          25       0.87      0.82      0.85        90\n",
            "\n",
            "    accuracy                           0.84      2560\n",
            "   macro avg       0.83      0.84      0.83      2560\n",
            "weighted avg       0.84      0.84      0.84      2560\n",
            "\n",
            "[[ 86   0   0   0   0   0   0   0   0   3   0   0   0   0   4   0   1   1\n",
            "    0   0   1   1   0   1   0   0]\n",
            " [  0  94   0   8   3   2   1   1   0   0   0   0   2   0   1   0   3  12\n",
            "    9   2   0   2   2   1   0   0]\n",
            " [  0   0  67   0   0   0   1   0   0   0   2   0   0   0   0   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   1  96   0   2   1   2   1   0   0   0   1   1   1   0   0   3\n",
            "    1   1   0   0   0   2   0   0]\n",
            " [  0   0   2   0  84   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    4   0   0   0   0   2   0   3]\n",
            " [  0   0   1   0   0  93   1   0   4   1   0   0   0   1   0   3   0   0\n",
            "    4   0   0   0   0   1   1   0]\n",
            " [  0   2   0   0   7   4  52   0   0   0   0   2   0   0   0   3   3   0\n",
            "    1   1   0   2   0   0   0   0]\n",
            " [  2   1   0   0   0   1   0  64   0   2   4   2   1   0   0   0   0   3\n",
            "    0   1   1   1   0   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0  77   4   0   0   0   0   0   1   0   0\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   1   0   0   0   4   1  89   0   0   0   0   0   0   0   0\n",
            "    1   0   0   0   0   1   2   2]\n",
            " [  1   0   3   0   1   0   1   4   0   0  82   1   0   0   0   0   0   7\n",
            "    0   0   0   0   0   2   0   0]\n",
            " [  0   0   1   0   0   0   1   0   0   0   0  81   0   0   0   0   3   2\n",
            "    3   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  91   1   2   0   0   0\n",
            "    0   0   3   0   0   0   0   0]\n",
            " [  0   1   0   2   0   1   0   3   0   0   0   0   3 102   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   2   2   5   0   0   2   0   0   0   0   0   0   2  66   1   5   3\n",
            "    0   0   2   0   3   0   0   0]\n",
            " [  0   2   0   1   0   3   5   0   1   0   0   0   0   0   0 105   0   0\n",
            "    0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0   2   0   1   3   0   0   0   1   0   0   1   0  73   1\n",
            "    1   0   0   0   0   1   2   0]\n",
            " [  0   3   0   0   0   0   3   8   0   0   2   0   1   0   0   0   1  74\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  2   1   0   0   0   1   2   0   4   3   0   1   0   0   0   0   2   0\n",
            "   59   0   0   0   0   0   0   4]\n",
            " [  1   0   2   1   1   3   0   0   0   0   1   3   0   0   0   0   0   2\n",
            "    0  97   0   0   0   2   5   1]\n",
            " [  1   0   1   0   0   0   0   0   0   0   3   0   2   1   0   0   0   0\n",
            "    0   1  92   0   3   1   2   0]\n",
            " [  0   0   0   0   0   0   2   2   0   0   1   0   0   0   0   0   0   0\n",
            "    1   1   0 110   3   0   1   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   9   0   0   0\n",
            "    0   0   2   2  73   0   1   0]\n",
            " [  0   0   0   1   0   0   0   0   2   3   6   3   0   0   0   0   1   0\n",
            "    0   1   0   0   0  76   2   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0\n",
            "    2   2   0   1   0   0  83   0]\n",
            " [  0   0   0   3   0   0   0   0   1   1   0   0   0   0   0   0   6   0\n",
            "    3   0   0   0   0   2   0  74]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "nnmodel = MLPClassifier(random_state=0)\n",
        "\n",
        "nnmodel.fit(cv_X_train_sc,cv_y_train)\n",
        "y_pred=nnmodel.predict(cv_X_test_sc)\n",
        "print(classification_report(y_pred,cv_y_test))\n",
        "cm=confusion_matrix(y_pred,cv_y_test)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcXfhaqH8Kjx",
        "outputId": "774c748a-d312-40c7-94dc-87df5092208e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        97\n",
            "           1       0.93      0.89      0.91       111\n",
            "           2       1.00      0.98      0.99        82\n",
            "           3       0.97      0.94      0.95       121\n",
            "           4       0.90      0.98      0.94        90\n",
            "           5       0.92      0.92      0.92       110\n",
            "           6       0.86      0.83      0.85        77\n",
            "           7       0.86      0.91      0.88        86\n",
            "           8       0.95      0.93      0.94        92\n",
            "           9       0.92      0.96      0.94       102\n",
            "          10       0.94      0.87      0.90       109\n",
            "          11       0.96      0.98      0.97        92\n",
            "          12       0.98      0.99      0.99       100\n",
            "          13       0.99      0.97      0.98       110\n",
            "          14       0.90      0.96      0.93        79\n",
            "          15       0.95      0.95      0.95       114\n",
            "          16       0.98      0.93      0.95       107\n",
            "          17       0.88      0.93      0.90       102\n",
            "          18       0.92      0.99      0.95        83\n",
            "          19       0.97      0.92      0.95       113\n",
            "          20       0.95      0.97      0.96        99\n",
            "          21       0.95      0.97      0.96       117\n",
            "          22       0.95      0.95      0.95        84\n",
            "          23       0.94      0.91      0.92        98\n",
            "          24       0.96      0.97      0.96        99\n",
            "          25       0.95      0.94      0.95        86\n",
            "\n",
            "    accuracy                           0.94      2560\n",
            "   macro avg       0.94      0.94      0.94      2560\n",
            "weighted avg       0.94      0.94      0.94      2560\n",
            "\n",
            "[[ 93   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   2   0   0   0   0   1]\n",
            " [  0  99   0   0   1   0   1   2   1   0   0   0   1   0   0   0   0   4\n",
            "    1   0   0   1   0   0   0   0]\n",
            " [  0   0  80   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0 114   0   1   1   1   0   0   1   0   0   0   0   0   0   1\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0  88   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   2 101   0   0   3   0   0   0   0   0   0   2   0   1\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   1   0   0   2   2  64   0   0   0   0   1   0   0   1   2   0   0\n",
            "    0   1   1   1   1   0   0   0]\n",
            " [  0   3   0   1   0   0   0  78   0   1   1   0   0   0   1   0   0   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  86   5   0   0   0   0   0   1   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0   0  98   0   0   0   0   0   0   0   0\n",
            "    1   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   3   0   0  95   1   0   0   1   0   0   4\n",
            "    0   0   0   0   0   3   0   0]\n",
            " [  0   0   0   0   1   0   1   0   0   0   0  90   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  99   0   1   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   1 107   0   0   0   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   1   0   0   0   0   0   0   0  76   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   1   0   0   0   0   0   0   0 108   1   0\n",
            "    0   1   0   0   0   0   1   0]\n",
            " [  0   0   0   1   2   0   1   0   0   1   0   0   0   0   2   0  99   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   1   2   0   0   0   0   0   1   0   0   0  95\n",
            "    1   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   82   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    1 104   0   0   1   2   1   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   1  96   0   2   0   0   0]\n",
            " [  0   1   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 114   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
            "    0   0   0   3  80   0   0   0]\n",
            " [  0   0   0   0   0   0   0   2   1   0   4   1   0   0   0   0   0   0\n",
            "    0   0   0   0   0  89   1   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "    0   0   0   1   0   0  96   0]\n",
            " [  0   0   0   0   1   0   0   0   0   1   0   0   0   0   1   0   0   0\n",
            "    2   0   0   0   0   0   0  81]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class=nnmodel.predict(X_Test_sc)\n",
        "print(classification_report(predicted_class,y_Test))\n",
        "cm=confusion_matrix(predicted_class,y_Test)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC22kjR81JI7",
        "outputId": "8b0be93b-ba74-4121-a2ab-bd8c6c179ed5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.96       161\n",
            "           1       0.96      0.90      0.93       144\n",
            "           2       0.94      0.96      0.95       139\n",
            "           3       0.94      0.92      0.93       171\n",
            "           4       0.91      0.97      0.94       143\n",
            "           5       0.92      0.92      0.92       153\n",
            "           6       0.91      0.90      0.91       167\n",
            "           7       0.87      0.89      0.88       148\n",
            "           8       0.95      0.93      0.94       167\n",
            "           9       0.93      0.94      0.93       146\n",
            "          10       0.95      0.90      0.92       154\n",
            "          11       0.94      0.95      0.95       154\n",
            "          12       0.98      0.93      0.96       151\n",
            "          13       0.93      0.93      0.93       165\n",
            "          14       0.92      0.95      0.93       135\n",
            "          15       0.94      0.93      0.94       169\n",
            "          16       0.96      0.94      0.95       172\n",
            "          17       0.90      0.92      0.91       157\n",
            "          18       0.91      0.94      0.92       157\n",
            "          19       0.97      0.94      0.95       157\n",
            "          20       0.96      0.99      0.98       163\n",
            "          21       0.95      0.97      0.96       133\n",
            "          22       0.98      0.96      0.97       141\n",
            "          23       0.94      0.94      0.94       158\n",
            "          24       0.92      0.97      0.95       138\n",
            "          25       0.96      0.96      0.96       157\n",
            "\n",
            "    accuracy                           0.94      4000\n",
            "   macro avg       0.94      0.94      0.94      4000\n",
            "weighted avg       0.94      0.94      0.94      4000\n",
            "\n",
            "[[152   0   0   0   0   0   1   2   0   0   0   0   0   0   0   0   2   0\n",
            "    1   0   1   0   0   0   1   1]\n",
            " [  0 130   0   4   1   1   0   1   0   0   0   1   1   0   0   0   0   1\n",
            "    0   0   0   3   0   1   0   0]\n",
            " [  0   0 134   0   3   0   0   0   0   0   1   0   0   0   1   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  2   0   0 157   0   0   1   2   1   0   0   1   0   1   1   1   1   3\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0 138   2   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "    1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 140   0   0   2   1   0   0   0   0   0   2   0   0\n",
            "    4   0   0   0   0   1   2   1]\n",
            " [  0   0   2   0   5   0 150   1   0   0   0   1   0   0   2   0   2   1\n",
            "    1   0   1   0   1   0   0   0]\n",
            " [  0   1   0   1   0   0   1 132   0   1   2   1   0   2   0   3   0   1\n",
            "    0   1   1   1   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0 156   4   0   0   0   1   0   1   0   0\n",
            "    1   0   0   0   0   2   1   0]\n",
            " [  0   0   0   0   0   2   0   0   3 137   0   2   0   1   0   0   0   0\n",
            "    1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0   2   0   0 138   0   0   0   1   0   1   6\n",
            "    0   0   0   0   1   4   0   0]\n",
            " [  0   0   1   0   2   0   2   0   0   0   0 147   0   0   0   0   0   0\n",
            "    1   0   0   0   0   0   0   1]\n",
            " [  0   0   1   1   0   0   1   2   0   0   0   0 141   4   0   0   0   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   1   0   0   0   2   0   2   0   0   0   0   1 154   2   0   0   2\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   2   0   0   0   1   0   1   0   0   0   1 128   1   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   4   2   0   1   0   0   0   0   0   0 158   0   1\n",
            "    0   0   0   0   0   0   3   0]\n",
            " [  0   0   1   0   0   0   1   2   0   0   0   1   0   0   3   1 161   0\n",
            "    1   0   0   0   0   0   0   1]\n",
            " [  0   1   0   0   0   0   3   3   0   0   2   0   0   1   1   0   0 145\n",
            "    0   1   0   0   0   0   0   0]\n",
            " [  1   2   0   0   0   0   0   0   1   3   0   1   0   0   0   1   0   0\n",
            "  147   0   0   0   0   0   0   1]\n",
            " [  0   0   1   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0 147   0   1   0   2   0   2]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 162   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0   0 129   0   0   3   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0\n",
            "    0   0   1   2 136   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   3   2   0   0   0   0   0   1\n",
            "    1   0   0   0   0 149   1   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   2   1   0   0   0 134   0]\n",
            " [  0   0   0   0   2   0   0   0   1   1   0   0   0   0   0   0   0   0\n",
            "    2   0   0   0   0   0   0 151]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#parameters = {'hidden_layer_sizes': [(100,),(100,3),(250,300)],'activation': ['tanh', 'relu','logistic'],'solver': ['sgd', 'adam','lbfgs'],'alpha': 10.0 ** -np.arange(1, 9),'learning_rate': ['constant','adaptive']}\n",
        "#clf = GridSearchCV(MLPClassifier(),param_grid = parameters, scoring = 'accuracy',cv = 5, n_jobs=-1)\n",
        "#clf.fit(cv_X_train_sc,cv_y_train)"
      ],
      "metadata": {
        "id": "OA0sPAJl8cR5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
        "#print(\"Accuracy :\",clf.best_score_)"
      ],
      "metadata": {
        "id": "-wZHuCleErlC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "dt = RandomForestClassifier(n_estimators=100)\n",
        "dt.fit(cv_X_train_sc,cv_y_train)\n",
        "y_pred=dt.predict(cv_X_test_sc)\n",
        "print(classification_report(y_pred,cv_y_test))\n",
        "cm=confusion_matrix(y_pred,cv_y_test)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "xK1_OL71cjKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04d6c87-c5a1-48a5-d406-1f82ae8ae123"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        96\n",
            "           1       0.93      0.86      0.90       116\n",
            "           2       0.96      0.97      0.97        79\n",
            "           3       0.97      0.94      0.96       122\n",
            "           4       0.93      0.93      0.93        98\n",
            "           5       0.93      0.93      0.93       110\n",
            "           6       0.93      0.91      0.92        76\n",
            "           7       0.92      0.93      0.93        90\n",
            "           8       0.93      0.99      0.96        86\n",
            "           9       0.94      0.95      0.95       105\n",
            "          10       0.94      0.90      0.92       106\n",
            "          11       0.95      0.98      0.96        91\n",
            "          12       0.96      0.95      0.96       102\n",
            "          13       0.97      1.00      0.99       105\n",
            "          14       0.93      0.95      0.94        82\n",
            "          15       0.95      0.96      0.96       112\n",
            "          16       0.96      0.92      0.94       106\n",
            "          17       0.95      0.91      0.93       113\n",
            "          18       0.96      0.97      0.96        88\n",
            "          19       0.95      0.97      0.96       105\n",
            "          20       0.91      0.98      0.94        94\n",
            "          21       0.93      0.99      0.96       112\n",
            "          22       1.00      0.94      0.97        89\n",
            "          23       0.97      0.97      0.97        95\n",
            "          24       0.97      0.98      0.97        99\n",
            "          25       0.93      0.95      0.94        83\n",
            "\n",
            "    accuracy                           0.95      2560\n",
            "   macro avg       0.95      0.95      0.95      2560\n",
            "weighted avg       0.95      0.95      0.95      2560\n",
            "\n",
            "[[ 93   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0 100   0   0   0   2   1   0   1   2   1   0   0   0   1   0   0   1\n",
            "    0   1   0   5   0   0   1   0]\n",
            " [  0   0  77   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   2   0   0   0   0   0]\n",
            " [  0   0   0 115   0   1   3   0   0   0   0   0   0   0   1   0   0   0\n",
            "    0   1   0   0   0   1   0   0]\n",
            " [  0   1   0   0  91   1   0   0   0   0   1   0   1   0   0   0   0   0\n",
            "    1   0   0   0   0   1   0   1]\n",
            " [  0   0   1   0   0 102   0   0   0   0   0   0   1   0   0   5   0   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   2   0  69   0   0   0   0   1   0   0   1   1   0   0\n",
            "    0   1   0   0   0   0   0   0]\n",
            " [  0   3   0   2   0   0   0  84   0   1   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0  85   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   4 100   0   1   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   1   0   1   2   0   0  95   1   0   0   0   0   0   3\n",
            "    0   0   1   0   0   1   0   0]\n",
            " [  0   0   1   0   1   0   0   0   0   0   0  89   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  97   0   0   0   0   0\n",
            "    0   0   5   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 105   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0   0   0   0   0   0   1  78   0   2   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0   1   0   0   0   0   0   0 108   0   0\n",
            "    0   0   0   1   0   0   0   0]\n",
            " [  0   0   1   0   2   0   0   0   0   2   0   1   0   0   1   0  97   0\n",
            "    0   0   0   0   0   0   0   2]\n",
            " [  0   1   0   0   0   0   0   3   0   0   2   0   0   1   0   0   0 103\n",
            "    2   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "   85   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 102   0   0   0   0   1   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   1  92   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
            "    0   0   0 111   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   2   0   0   0\n",
            "    0   0   0   2  84   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   1   0   0   0   0   0   0\n",
            "    0   0   0   0   0  92   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   1   0   1   0   0  97   0]\n",
            " [  0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   1   0\n",
            "    1   0   0   0   0   0   0  79]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "#parameters = [{'n_estimaters;:[100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400] ,'criterion':['gini','entropy'],'bootstrap': False}]\n",
        "#grid_search = GridSearchCV(estimator =dt,param_grid = parameters,scoring = 'accuracy',cv = 5,verbose=0)\n",
        "#grid_search.fit(cv_X_train_sc,cv_y_train)"
      ],
      "metadata": {
        "id": "TtCC6h1F3bGx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Tuned Hyperparameters :\", grid_search.best_params_)\n",
        "#print(\"Accuracy :\",grid_search.best_score_)"
      ],
      "metadata": {
        "id": "AU_1k_wG36GT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class=dt.predict(X_Test_sc)\n",
        "print(classification_report(predicted_class,y_Test))\n",
        "cm=confusion_matrix(predicted_class,y_Test)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhF33dmq2V4d",
        "outputId": "9e23c0d2-508c-4520-f12b-8fb82a0fb441"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       153\n",
            "           1       0.97      0.87      0.92       151\n",
            "           2       0.96      0.98      0.97       139\n",
            "           3       0.98      0.90      0.93       182\n",
            "           4       0.96      0.95      0.95       154\n",
            "           5       0.93      0.93      0.93       153\n",
            "           6       0.96      0.93      0.94       169\n",
            "           7       0.85      0.93      0.89       138\n",
            "           8       0.93      0.96      0.94       159\n",
            "           9       0.95      0.97      0.96       144\n",
            "          10       0.91      0.92      0.92       144\n",
            "          11       0.96      0.97      0.97       155\n",
            "          12       0.97      0.96      0.97       146\n",
            "          13       0.93      0.98      0.96       158\n",
            "          14       0.95      0.92      0.94       143\n",
            "          15       0.93      0.94      0.94       167\n",
            "          16       0.96      0.94      0.95       173\n",
            "          17       0.96      0.91      0.93       171\n",
            "          18       0.98      0.99      0.98       159\n",
            "          19       0.95      0.98      0.96       146\n",
            "          20       0.96      0.99      0.98       164\n",
            "          21       0.94      0.97      0.96       132\n",
            "          22       0.99      0.96      0.98       142\n",
            "          23       0.97      0.95      0.96       162\n",
            "          24       0.94      0.95      0.95       144\n",
            "          25       0.93      0.97      0.95       152\n",
            "\n",
            "    accuracy                           0.95      4000\n",
            "   macro avg       0.95      0.95      0.95      4000\n",
            "weighted avg       0.95      0.95      0.95      4000\n",
            "\n",
            "[[153   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0 132   0   0   0   2   2   0   1   0   1   1   1   1   1   2   1   1\n",
            "    1   0   1   2   0   1   0   0]\n",
            " [  0   0 136   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   1   0 163   0   0   2   5   2   0   2   0   0   2   1   1   1   0\n",
            "    0   1   0   0   0   0   0   1]\n",
            " [  0   0   0   0 146   1   0   1   0   1   2   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   1   0   2]\n",
            " [  0   0   0   0   0 142   0   0   1   0   1   0   0   0   0   6   0   0\n",
            "    0   1   0   0   0   0   0   2]\n",
            " [  0   0   4   0   2   0 157   1   0   0   0   0   2   0   1   0   0   0\n",
            "    0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   3   0   0   0 129   0   0   3   0   0   1   0   0   0   0\n",
            "    1   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0 153   6   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   2 140   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   2]\n",
            " [  0   0   0   0   0   0   0   4   0   0 133   0   0   0   0   0   0   4\n",
            "    0   0   1   0   0   2   0   0]\n",
            " [  0   0   0   0   1   0   0   0   1   0   0 151   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   2]\n",
            " [  0   0   0   0   0   0   1   2   0   0   0   0 140   2   0   0   0   0\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0 155   0   0   0   1\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   0   2   1   0   0   2   0   0   0   0   0   0   2 132   0   3   0\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   6   0   0   4   0   0   0   0   0   0 157   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   2   0   0   0   1   0   0   3   0 162   0\n",
            "    2   0   0   0   0   0   2   1]\n",
            " [  0   2   0   0   0   0   0   7   0   0   2   2   0   1   0   0   0 155\n",
            "    0   1   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  157   2   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 143   0   1   0   0   2   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0 162   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0\n",
            "    0   0   0 128   0   0   2   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0\n",
            "    0   0   0   3 137   0   0   0]\n",
            " [  0   1   0   0   2   0   0   0   1   0   1   2   0   0   0   0   0   0\n",
            "    0   0   0   0   0 154   0   1]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "    0   2   0   1   0   0 137   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   1   0   1   0\n",
            "    0   1   0   0   0   0   1 147]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "dt = RandomForestClassifier(n_estimators=100)\n",
        "dt.fit(X_Train_sc,y_Train)\n",
        "y_pred=dt.predict(X_Test_sc)\n",
        "print(classification_report(y_pred,y_Test))\n",
        "cm=confusion_matrix(y_pred,y_Test)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws6rnS0v4Vnb",
        "outputId": "bc82fe06-d94a-4205-c510-f1c0632c7e8c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       154\n",
            "           1       0.98      0.89      0.93       150\n",
            "           2       0.96      0.99      0.97       137\n",
            "           3       0.99      0.93      0.96       178\n",
            "           4       0.97      0.92      0.95       159\n",
            "           5       0.95      0.96      0.96       152\n",
            "           6       0.98      0.98      0.98       163\n",
            "           7       0.89      0.95      0.92       141\n",
            "           8       0.95      0.96      0.95       162\n",
            "           9       0.95      0.96      0.96       147\n",
            "          10       0.94      0.95      0.94       144\n",
            "          11       0.97      0.99      0.98       155\n",
            "          12       0.99      0.96      0.98       149\n",
            "          13       0.92      0.98      0.95       156\n",
            "          14       0.96      0.94      0.95       143\n",
            "          15       0.94      0.97      0.95       163\n",
            "          16       0.96      0.96      0.96       168\n",
            "          17       0.98      0.92      0.95       170\n",
            "          18       0.96      0.99      0.98       156\n",
            "          19       0.97      0.99      0.98       148\n",
            "          20       0.99      0.99      0.99       167\n",
            "          21       0.96      0.96      0.96       135\n",
            "          22       0.99      0.97      0.98       141\n",
            "          23       0.98      0.96      0.97       163\n",
            "          24       0.97      0.96      0.96       146\n",
            "          25       0.96      0.99      0.98       153\n",
            "\n",
            "    accuracy                           0.96      4000\n",
            "   macro avg       0.96      0.96      0.96      4000\n",
            "weighted avg       0.96      0.96      0.96      4000\n",
            "\n",
            "[[154   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0 133   0   0   0   2   1   3   0   0   1   1   0   0   1   2   0   1\n",
            "    2   0   0   3   0   0   0   0]\n",
            " [  0   0 136   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 165   0   0   1   3   1   0   0   0   0   3   1   1   1   0\n",
            "    0   1   0   0   0   0   1   0]\n",
            " [  0   0   1   0 147   1   0   1   0   1   2   0   0   0   0   0   0   0\n",
            "    3   0   0   0   0   0   0   3]\n",
            " [  0   0   0   0   0 146   0   0   2   0   0   0   0   0   0   3   0   0\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  0   0   1   0   1   0 160   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   2   0   0   0 134   0   0   2   0   0   1   0   1   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 156   6   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   5 141   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   2   0   0 137   0   0   0   0   0   0   2\n",
            "    0   0   0   0   0   3   0   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0 153   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   0   0   1   1   0   0   0   0 143   3   0   0   0   0\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0 153   0   0   0   1\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   1   0   0   0   1   0   0   0   0   0   0   2 134   0   4   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   1   1   0   0   0   0   0   0 158   0   0\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   1   0   0   2   0 162   0\n",
            "    1   0   0   0   0   0   1   0]\n",
            " [  0   1   0   0   0   0   0   5   0   0   2   0   0   2   1   0   1 157\n",
            "    0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  155   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 147   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 166   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0\n",
            "    0   0   1 130   0   0   2   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0\n",
            "    0   0   0   1 137   0   0   0]\n",
            " [  0   1   0   0   2   0   0   0   0   0   2   2   0   0   0   0   0   0\n",
            "    0   0   0   0   0 156   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
            "    0   1   0   1   0   0 140   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   1   0   0   0   0   0 152]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nnmodel1 = MLPClassifier()\n",
        "nnmodel1.fit(X_Train_sc,y_Train)\n",
        "y_pred=nnmodel1.predict(X_Test_sc)\n",
        "print(classification_report(y_pred,y_Test))\n",
        "cm=confusion_matrix(y_pred,y_Test)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSyOVabm59tF",
        "outputId": "ab754b90-6f19-496a-9cb7-48dd9ae7946a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       157\n",
            "           1       0.95      0.91      0.93       141\n",
            "           2       0.96      0.98      0.97       139\n",
            "           3       0.96      0.93      0.94       174\n",
            "           4       0.97      0.95      0.96       155\n",
            "           5       0.97      0.90      0.93       165\n",
            "           6       0.95      0.97      0.96       159\n",
            "           7       0.88      0.96      0.92       139\n",
            "           8       0.95      0.96      0.95       163\n",
            "           9       0.94      0.91      0.93       152\n",
            "          10       0.96      0.96      0.96       146\n",
            "          11       0.93      0.97      0.95       150\n",
            "          12       0.99      0.95      0.97       149\n",
            "          13       0.94      0.98      0.96       159\n",
            "          14       0.94      0.96      0.95       135\n",
            "          15       0.92      0.96      0.94       161\n",
            "          16       0.96      0.98      0.97       166\n",
            "          17       0.97      0.92      0.95       169\n",
            "          18       0.95      0.97      0.96       158\n",
            "          19       0.99      0.94      0.96       158\n",
            "          20       0.98      0.99      0.98       165\n",
            "          21       0.97      0.97      0.97       136\n",
            "          22       0.99      0.97      0.98       142\n",
            "          23       0.96      0.95      0.96       161\n",
            "          24       0.94      0.94      0.94       145\n",
            "          25       0.96      0.97      0.97       156\n",
            "\n",
            "    accuracy                           0.95      4000\n",
            "   macro avg       0.95      0.95      0.95      4000\n",
            "weighted avg       0.95      0.95      0.95      4000\n",
            "\n",
            "[[149   0   0   0   0   0   0   1   0   1   0   0   0   0   2   0   3   0\n",
            "    1   0   0   0   0   0   0   0]\n",
            " [  0 129   0   2   0   0   0   1   0   0   0   1   1   0   1   1   0   1\n",
            "    1   0   0   2   0   1   0   0]\n",
            " [  0   0 136   0   2   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  1   2   0 161   0   0   0   2   1   0   0   1   0   1   1   1   1   1\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   0   2   0 147   1   2   0   0   0   0   2   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  1   0   0   0   0 148   0   0   1   1   1   0   0   0   0   8   0   0\n",
            "    1   0   0   0   0   1   2   1]\n",
            " [  0   0   0   0   1   0 155   2   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0 133   0   0   1   1   0   2   0   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0 156   5   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0   5 139   0   2   0   1   0   1   0   0\n",
            "    1   0   0   0   0   0   1   2]\n",
            " [  0   0   1   0   0   0   0   2   0   0 140   0   0   0   0   0   0   2\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0   1   0   0   1   0   0   0 146   0   1   0   0   0   0\n",
            "    1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   2   0   0   0   0 142   2   1   0   0   0\n",
            "    0   0   1   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0   2   0   0   0   0   1 156   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   2   0   0   1   0   0   0   0 130   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0   0   0   0   0   0   1   1 154   0   1\n",
            "    0   0   0   0   0   0   2   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   2   1 162   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   1   0   1   2   1   0   0   2   1   0   1   0   0   0 156\n",
            "    0   0   0   0   1   1   0   0]\n",
            " [  1   2   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0   0\n",
            "  153   0   0   0   0   0   0   0]\n",
            " [  0   0   1   2   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 149   0   1   0   0   1   2]\n",
            " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 164   0   0   0   0   0]\n",
            " [  0   0   1   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 132   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0   0   0\n",
            "    0   0   2   0 138   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   1   0   2   1   0   0   0   0   0   0\n",
            "    1   1   0   0   0 153   1   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   1   0   0   0   2   0   0\n",
            "    0   1   0   1   0   0 136   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
            "    2   0   0   0   0   0   0 152]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_Train_mm = scaler.transform(df_Train)\n",
        "#X_train_mm = scaler.transform(X_train)\n",
        "#X_test_mm = scaler.transform(X_test)\n",
        "#cv_X_train_mm = scaler.transform(cv_X_train)\n",
        "#cv_X_test_mm = scaler.transform(cv_X_test)\n",
        "#X_Test_mm = scaler.transform(df_Test)\n",
        "\n",
        "colnames1 = colnames[1:]\n",
        "print(colnames1)\n",
        "df_Train_mm = pd.DataFrame(X_Train_mm, columns = colnames1)\n",
        "df_Test_mm = pd.DataFrame(X_Test_mm, columns = colnames1)\n",
        "df_X_train_mm = pd.DataFrame(X_train_mm, columns = colnames1)\n",
        "df_cv_X_train_mm = pd.DataFrame(cv_X_train_mm, columns = colnames1)\n",
        "df_cv_X_test_mm = pd.DataFrame(cv_X_test_mm, columns = colnames1)\n",
        "df_X_test_mm = pd.DataFrame(X_test_mm, columns = colnames1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XkNzm8TUCpV",
        "outputId": "d8ab99ee-3a55-46e2-c250-c32b5b8c4c26"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler2 = StandardScaler()\n",
        "scaler2.fit(df_Train_mm)\n",
        "\n",
        "X_Train_mm_sc = scaler2.transform(df_Train_mm)\n",
        "X_train_mm_sc = scaler2.transform(df_X_train_mm)\n",
        "X_test_mm_sc = scaler2.transform(df_X_test_mm)\n",
        "cv_X_train_mm_sc = scaler2.transform(df_cv_X_train_mm)\n",
        "cv_X_test_mm_sc = scaler2.transform(df_cv_X_test_mm)\n",
        "X_Test_mm_sc = scaler2.transform(df_Test_mm)"
      ],
      "metadata": {
        "id": "yZHYH0srVza7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ShuffleSplit,cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "dt = RandomForestClassifier(n_estimators=100)\n",
        "dt.fit(X_Train_mm_sc,y_Train)\n",
        "y_pred=dt.predict(X_Test_mm_sc)\n",
        "print(classification_report(y_pred,y_Test))\n",
        "cm=confusion_matrix(y_pred,y_Test)\n",
        "print(cm)\n",
        "cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "scores = cross_val_score(dt, X_Train_mm_sc, y_Train, cv=cv1)\n",
        "print ('Cross validation', scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdLam4a-WbGh",
        "outputId": "4d50ac15-38dc-4bd4-ebbe-c4e03f411794"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       154\n",
            "           1       0.98      0.89      0.93       150\n",
            "           2       0.96      0.99      0.98       139\n",
            "           3       0.99      0.94      0.96       176\n",
            "           4       0.97      0.93      0.95       159\n",
            "           5       0.96      0.96      0.96       153\n",
            "           6       0.97      0.97      0.97       164\n",
            "           7       0.87      0.93      0.90       142\n",
            "           8       0.95      0.97      0.96       161\n",
            "           9       0.95      0.95      0.95       148\n",
            "          10       0.91      0.94      0.93       141\n",
            "          11       0.94      0.99      0.97       149\n",
            "          12       0.99      0.96      0.98       149\n",
            "          13       0.92      0.98      0.95       156\n",
            "          14       0.96      0.93      0.95       144\n",
            "          15       0.95      0.96      0.96       167\n",
            "          16       0.96      0.95      0.96       169\n",
            "          17       0.97      0.92      0.95       169\n",
            "          18       0.97      1.00      0.98       156\n",
            "          19       0.97      1.00      0.99       147\n",
            "          20       0.99      0.99      0.99       168\n",
            "          21       0.96      0.96      0.96       136\n",
            "          22       0.99      0.98      0.98       140\n",
            "          23       0.98      0.94      0.96       166\n",
            "          24       0.95      0.97      0.96       142\n",
            "          25       0.97      0.99      0.98       155\n",
            "\n",
            "    accuracy                           0.96      4000\n",
            "   macro avg       0.96      0.96      0.96      4000\n",
            "weighted avg       0.96      0.96      0.96      4000\n",
            "\n",
            "[[154   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0 133   0   0   0   2   1   3   0   0   1   1   0   1   1   2   0   1\n",
            "    1   0   0   3   0   0   0   0]\n",
            " [  0   0 137   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 165   0   0   1   3   1   0   0   0   0   2   1   0   1   0\n",
            "    0   0   0   0   0   0   1   1]\n",
            " [  0   0   1   0 148   1   0   1   0   1   2   0   0   0   0   0   0   0\n",
            "    3   0   0   0   0   0   0   2]\n",
            " [  0   0   0   0   0 147   0   0   1   0   0   0   0   0   0   4   0   0\n",
            "    0   0   0   1   0   0   0   0]\n",
            " [  0   0   2   0   1   0 159   1   0   0   0   1   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   2   0   0   0 132   0   0   3   1   0   1   0   0   0   1\n",
            "    1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 156   5   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   6 141   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   3   0   0 133   0   0   0   0   0   0   2\n",
            "    0   0   0   0   0   3   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 148   0   0   0   0   0   0\n",
            "    0   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   2   0   0   0   0 143   2   0   0   0   0\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0 153   0   0   0   1\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   0   1   1   0   0   0   0   0   2 134   0   5   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   1   1   0   0   0   0   0   0 160   0   0\n",
            "    0   0   0   1   0   0   2   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   2   0   0   2   0 161   0\n",
            "    0   0   0   0   0   0   2   1]\n",
            " [  0   1   0   0   0   0   0   4   0   0   3   0   0   2   1   0   1 156\n",
            "    0   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  156   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 147   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0 166   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0\n",
            "    0   0   1 131   0   0   2   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   1   0   0\n",
            "    0   0   0   0 137   0   0   0]\n",
            " [  0   1   0   0   2   0   0   0   0   0   3   4   0   0   0   0   0   0\n",
            "    0   0   0   0   0 156   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "    0   1   0   0   0   0 138   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
            "    0   1   0   0   0   0   0 153]]\n",
            "Cross validation [0.9546875 0.9571875 0.9578125 0.9565625 0.9578125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ShuffleSplit,cross_val_score\n",
        "nnmodel2 = MLPClassifier()\n",
        "nnmodel2.fit(X_Train_mm_sc,y_Train)\n",
        "y_pred=nnmodel2.predict(X_Test_mm_sc)\n",
        "print(classification_report(y_pred,y_Test))\n",
        "cm=confusion_matrix(y_pred,y_Test)\n",
        "print(cm)\n",
        "cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "scores = cross_val_score(nnmodel2, X_Train_mm_sc, y_Train, cv=cv1)\n",
        "print ('Cross validation', scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu5cRyODW0jH",
        "outputId": "f21a0a87-88d1-49a8-ac33-772763ef1d64"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       157\n",
            "           1       0.94      0.90      0.92       142\n",
            "           2       0.96      0.95      0.95       143\n",
            "           3       0.95      0.95      0.95       166\n",
            "           4       0.92      0.93      0.92       151\n",
            "           5       0.96      0.89      0.92       166\n",
            "           6       0.95      0.91      0.93       171\n",
            "           7       0.87      0.90      0.89       145\n",
            "           8       0.94      0.93      0.94       166\n",
            "           9       0.95      0.95      0.95       148\n",
            "          10       0.97      0.92      0.94       153\n",
            "          11       0.94      0.98      0.96       150\n",
            "          12       0.99      0.97      0.98       146\n",
            "          13       0.95      0.97      0.96       163\n",
            "          14       0.92      0.96      0.94       133\n",
            "          15       0.92      0.95      0.93       164\n",
            "          16       0.96      0.97      0.96       166\n",
            "          17       0.91      0.94      0.92       156\n",
            "          18       0.97      0.96      0.97       162\n",
            "          19       0.99      0.97      0.98       154\n",
            "          20       0.96      0.97      0.97       167\n",
            "          21       0.96      0.96      0.96       135\n",
            "          22       0.99      0.99      0.99       138\n",
            "          23       0.97      0.95      0.96       163\n",
            "          24       0.94      0.96      0.95       141\n",
            "          25       0.96      0.98      0.97       154\n",
            "\n",
            "    accuracy                           0.95      4000\n",
            "   macro avg       0.95      0.95      0.95      4000\n",
            "weighted avg       0.95      0.95      0.95      4000\n",
            "\n",
            "[[152   0   1   0   0   0   0   0   0   1   0   0   0   0   1   0   1   0\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  1 128   0   2   0   0   0   3   0   0   0   1   0   0   1   0   0   1\n",
            "    1   0   0   3   0   1   0   0]\n",
            " [  0   0 136   0   3   0   0   1   0   0   0   1   0   0   0   1   0   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  1   0   0 158   0   0   0   1   0   0   0   1   0   2   2   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   2   0 140   1   1   1   0   0   0   2   0   0   0   0   0   0\n",
            "    2   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   1 147   0   0   2   0   0   0   0   0   0   8   0   0\n",
            "    1   0   0   0   0   1   5   1]\n",
            " [  0   0   1   0   5   0 155   2   0   0   0   0   0   1   1   1   1   2\n",
            "    0   0   1   0   1   0   0   0]\n",
            " [  0   0   0   2   0   0   1 131   0   0   1   0   0   3   2   0   2   2\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  1   2   0   1   0   0   0   0 155   4   0   1   0   1   0   1   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   4 141   0   0   0   0   1   0   0   0\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0   4   0   0 141   0   0   0   0   0   0   6\n",
            "    0   0   0   0   0   2   0   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0 147   0   0   0   0   0   1\n",
            "    0   0   0   1   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   2   0   0   0   0 142   0   0   0   0   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   2   0   0   0   1   0 158   0   0   0   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   1   0   0   1   0   0   0   0 128   0   1   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   1   0   3   3   0   1   0   0   0   0   0   0 155   0   0\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   0   0   0   1   0   0   1   0   0   0   0   0   0   3   0 161   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   2   0   0   2   1   0   0   2   0   0   1   0   0   0 146\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   1   1   1   0   0   0   1   0   0\n",
            "  156   0   0   0   0   0   0   1]\n",
            " [  0   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0 150   0   0   0   0   0   2]\n",
            " [  0   1   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
            "    0   0 162   1   0   0   1   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   1   0   0   0   1   0\n",
            "    0   0   2 130   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0 137   0   0   0]\n",
            " [  0   0   0   0   1   0   0   0   1   0   1   2   0   0   0   0   0   1\n",
            "    0   0   0   0   0 155   1   1]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "    0   1   1   1   0   0 136   0]\n",
            " [  0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0\n",
            "    1   0   0   0   0   0   0 151]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation [0.939375  0.9446875 0.9415625 0.95      0.9428125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import plot_confusion_matrix\n",
        "# print(y_Train)\n",
        "# plot_confusion_matrix(nnmodel2, X_Test_mm_sc,y_Test)"
      ],
      "metadata": {
        "id": "iZyLRh1f5pJw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#parameters = {'hidden_layer_sizes': [(100,),(100,10),(100,20),(100,30)],'activation': ['tanh', 'relu'],'solver': ['sgd', 'adam','lbfgs'],'alpha': 10.0 ** -np.arange(1, 10),'learning_rate': ['constant','adaptive']}\n",
        "#clf = GridSearchCV(MLPClassifier(),param_grid = parameters, scoring = 'accuracy',cv = 5, n_jobs=-1)\n",
        "#clf.fit(cv_X_train_mm_sc,cv_y_train)\n"
      ],
      "metadata": {
        "id": "KaieKGX0djF4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
        "#print(\"Accuracy :\",clf.best_score_)"
      ],
      "metadata": {
        "id": "DPBdHkUNdstR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nnmodel3 = MLPClassifier(hidden_layer_sizes=(250,300),activation='logistic')\n",
        "nnmodel3.fit(X_Train_mm_sc,y_Train)\n",
        "y_pred=nnmodel3.predict(X_Test_mm_sc)\n",
        "print(classification_report(y_pred,y_Test))\n",
        "cm=confusion_matrix(y_pred,y_Test)\n",
        "print(cm)\n",
        "cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "scores = cross_val_score(nnmodel2, X_Train_mm_sc, y_Train, cv=cv1)\n",
        "print ('Cross validation', scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_wVpDzxx-ql",
        "outputId": "29de7ecf-e717-4147-cccc-f48584130145"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       154\n",
            "           1       0.99      0.93      0.96       144\n",
            "           2       0.99      0.99      0.99       141\n",
            "           3       0.99      0.96      0.98       171\n",
            "           4       0.97      0.99      0.98       149\n",
            "           5       0.98      0.95      0.96       158\n",
            "           6       0.96      0.98      0.97       162\n",
            "           7       0.95      0.96      0.96       150\n",
            "           8       0.95      0.99      0.97       158\n",
            "           9       0.98      0.97      0.97       150\n",
            "          10       0.97      0.98      0.97       144\n",
            "          11       0.96      0.99      0.97       153\n",
            "          12       1.00      0.99      1.00       145\n",
            "          13       0.98      0.99      0.98       164\n",
            "          14       0.94      0.98      0.96       134\n",
            "          15       0.97      0.96      0.97       169\n",
            "          16       0.97      0.96      0.97       169\n",
            "          17       0.98      0.96      0.97       164\n",
            "          18       0.99      0.98      0.98       162\n",
            "          19       0.99      0.99      0.99       152\n",
            "          20       0.99      1.00      1.00       167\n",
            "          21       0.98      0.99      0.99       134\n",
            "          22       0.99      1.00      1.00       138\n",
            "          23       0.99      0.98      0.98       162\n",
            "          24       0.97      0.95      0.96       148\n",
            "          25       0.99      0.99      0.99       158\n",
            "\n",
            "    accuracy                           0.98      4000\n",
            "   macro avg       0.98      0.98      0.98      4000\n",
            "weighted avg       0.98      0.98      0.98      4000\n",
            "\n",
            "[[152   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0 134   0   1   0   0   1   1   0   0   0   1   0   0   1   1   0   1\n",
            "    0   0   1   1   0   1   0   0]\n",
            " [  0   0 140   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0 165   0   0   0   0   1   0   0   0   0   1   2   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 147   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "    1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1 150   0   0   2   1   0   0   0   0   0   2   0   0\n",
            "    0   0   0   0   0   0   1   1]\n",
            " [  0   0   0   0   1   0 158   1   0   0   0   1   0   0   0   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1 144   0   0   1   1   0   1   1   0   0   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 156   2   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   5 145   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0 141   0   0   0   0   0   0   1\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   1   0   1   0   0   0   0 151   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0 144   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   2   0   0   0   0   0 162   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0   0   0   0   0   0   1 131   0   1   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2   1   0   0   0   0   0   0   0   1 163   0   0\n",
            "    0   0   0   0   0   0   2   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   3   2 163   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   1   0   0   3   0   0   1   0   0   0 158\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   1   0   0   1   0   0   0   0   0   0\n",
            "  159   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 150   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 167   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 133   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0 138   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0   0   0\n",
            "    1   0   0   0   0 158   1   0]\n",
            " [  3   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
            "    0   1   0   1   0   0 141   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0 157]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation [0.9396875 0.946875  0.9490625 0.9471875 0.9440625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ShuffleSplit,cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "dt = RandomForestClassifier(bootstrap= False,n_estimators=1400)\n",
        "dt.fit(X_Train_mm_sc,y_Train)\n",
        "y_pred=dt.predict(X_Test_mm_sc)\n",
        "print(classification_report(y_pred,y_Test))\n",
        "cm=confusion_matrix(y_pred,y_Test)\n",
        "print(cm)\n",
        "cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "scores = cross_val_score(dt, X_Train_mm_sc, y_Train, cv=cv1)\n",
        "print ('Cross validation', scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUSe-EPQaaRa",
        "outputId": "8cef68fc-8784-470f-b06e-5924e72f072b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       154\n",
            "           1       0.99      0.91      0.94       148\n",
            "           2       0.97      0.99      0.98       139\n",
            "           3       0.99      0.94      0.97       176\n",
            "           4       0.97      0.97      0.97       152\n",
            "           5       0.96      0.97      0.97       151\n",
            "           6       0.98      0.98      0.98       164\n",
            "           7       0.89      0.96      0.92       140\n",
            "           8       0.96      0.96      0.96       164\n",
            "           9       0.96      0.97      0.96       147\n",
            "          10       0.92      0.94      0.93       143\n",
            "          11       0.97      0.99      0.98       154\n",
            "          12       1.00      0.97      0.99       148\n",
            "          13       0.93      0.98      0.95       157\n",
            "          14       0.98      0.94      0.96       144\n",
            "          15       0.96      0.96      0.96       167\n",
            "          16       0.96      0.97      0.97       167\n",
            "          17       0.98      0.93      0.96       169\n",
            "          18       0.99      1.00      0.99       159\n",
            "          19       0.99      1.00      0.99       149\n",
            "          20       0.99      0.99      0.99       168\n",
            "          21       0.96      0.97      0.97       135\n",
            "          22       0.99      0.99      0.99       138\n",
            "          23       0.97      0.95      0.96       163\n",
            "          24       0.97      0.96      0.96       146\n",
            "          25       0.99      0.99      0.99       158\n",
            "\n",
            "    accuracy                           0.97      4000\n",
            "   macro avg       0.97      0.97      0.97      4000\n",
            "weighted avg       0.97      0.97      0.97      4000\n",
            "\n",
            "[[154   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0 134   0   0   0   1   1   3   0   0   1   1   0   0   1   2   0   0\n",
            "    1   0   0   3   0   0   0   0]\n",
            " [  0   0 138   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 166   0   0   1   3   1   0   0   0   0   2   1   0   1   0\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   0   0   0 147   1   0   1   0   0   2   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0   0 147   0   0   1   0   0   0   0   0   0   3   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   2   0   1   0 160   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   1   0   0   0 134   0   0   3   0   0   1   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 158   6   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   4 142   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0   0 135   0   0   0   0   0   0   2\n",
            "    0   0   0   0   0   3   0   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0 153   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   1   0   0   0   0 144   1   0   0   0   0\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0 154   0   0   0   1\n",
            "    0   0   0   0   1   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0   0   0   0   0   2 136   0   4   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0   0   1   0   0   0   0   0   0 161   0   0\n",
            "    0   0   0   1   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0 162   0\n",
            "    1   0   0   0   0   0   1   1]\n",
            " [  0   0   0   0   0   0   0   4   0   0   2   0   0   4   0   0   1 158\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  159   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 149   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0 166   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "    0   0   1 131   0   0   2   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0 137   0   0   0]\n",
            " [  0   1   0   0   2   0   0   0   0   0   3   2   0   0   0   0   0   0\n",
            "    0   0   0   0   0 155   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
            "    0   1   0   1   0   0 140   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   1   0   0   0   0   0 157]]\n",
            "Cross validation [0.960625  0.9640625 0.963125  0.961875  0.9621875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "X5SQZ2C9MWDJ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  # tf.keras.layers.Normalization(axis=None),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(26,activation='sigmoid')\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_Train_mm_sc,\n",
        "    y_Train,\n",
        "    epochs=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcCqXlwl4Jka",
        "outputId": "0a4b8c4b-dcb3-4b52-96f8-42e8d21d78c4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 2s 3ms/step - loss: 1.2541 - sparse_categorical_accuracy: 0.6528\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.5701 - sparse_categorical_accuracy: 0.8316\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.4104 - sparse_categorical_accuracy: 0.8773\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.3223 - sparse_categorical_accuracy: 0.9039\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.2627 - sparse_categorical_accuracy: 0.9186\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.2223 - sparse_categorical_accuracy: 0.9316\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1907 - sparse_categorical_accuracy: 0.9406\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9486\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1464 - sparse_categorical_accuracy: 0.9544\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9597\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1188 - sparse_categorical_accuracy: 0.9623\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1034 - sparse_categorical_accuracy: 0.9684\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0999 - sparse_categorical_accuracy: 0.9664\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9730\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9746\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9772\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9789\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9783\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9833\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9829\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0478 - sparse_categorical_accuracy: 0.9847\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9859\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0426 - sparse_categorical_accuracy: 0.9868\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0406 - sparse_categorical_accuracy: 0.9876\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9894\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9890\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9905\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9911\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9913\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0264 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0304 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9938\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9913\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9927\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9940\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0181 - sparse_categorical_accuracy: 0.9951\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9944\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0222 - sparse_categorical_accuracy: 0.9935\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9955\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0228 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0201 - sparse_categorical_accuracy: 0.9956\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0135 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0279 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9943\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9934\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0126 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0157 - sparse_categorical_accuracy: 0.9946\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0281 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9992\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0010 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9947\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9911\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0360 - sparse_categorical_accuracy: 0.9887\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0201 - sparse_categorical_accuracy: 0.9939\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0204 - sparse_categorical_accuracy: 0.9934\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9958\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 7.8652e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 5.8638e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9997\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0332 - sparse_categorical_accuracy: 0.9895\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 9.9387e-04 - sparse_categorical_accuracy: 0.9999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd934c5790>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "XM3tS3m2OKcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee34ad08-b019-48f8-e8e2-60ad0f8f1b6a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (32, 128)                 2176      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (32, 128)                 16512     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (32, 26)                  3354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,042\n",
            "Trainable params: 22,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  weights = layer.get_weights()\n",
        "  #print(weights)"
      ],
      "metadata": {
        "id": "zefICB9P5Og-"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True,)"
      ],
      "metadata": {
        "id": "rVR_KYr45UIZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "1c91ea4b-0402-4717-f0b4-9ce0fc5a40af"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_Test_mm_sc, y_Test,verbose=1)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "8v0Wq1tU5YI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67c12f7-c323-495c-9bf0-2634e22e5530"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1460 - sparse_categorical_accuracy: 0.9697\n",
            "[0.1459594964981079, 0.9697499871253967]\n"
          ]
        }
      ]
    }
  ]
}